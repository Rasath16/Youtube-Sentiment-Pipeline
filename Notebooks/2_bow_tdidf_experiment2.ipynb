{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries for MLflow and S3 artifact storage\n",
        "%pip install -q mlflow boto3 awscli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MLflow Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mlflow_config"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://mlfow-bucket-2025/111723537539582833', creation_time=1762929091542, experiment_id='111723537539582833', last_update_time=1762929091542, lifecycle_stage='active', name='Experiment 2 - BoW vs TfIdf', tags={'mlflow.experimentKind': 'custom_model_development'}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the remote tracking server URI\n",
        "mlflow.set_tracking_uri(\"http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/\")\n",
        "\n",
        "# Set or create a new experiment\n",
        "mlflow.set_experiment(\"Experiment 2 - BoW vs TfIdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "load_and_clean_data"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../data/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
        "# Display the shape after final cleaning\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>family mormon never tried explain still stare ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buddhism much lot compatible christianity espe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seriously say thing first get complex explain ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>learned want teach different focus goal not wr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>benefit may want read living buddha living chr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       clean_comment  category\n",
              "0  family mormon never tried explain still stare ...         1\n",
              "1  buddhism much lot compatible christianity espe...         1\n",
              "2  seriously say thing first get complex explain ...        -1\n",
              "3  learned want teach different focus goal not wr...         0\n",
              "4  benefit may want read living buddha living chr...         1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clean_comment    0\n",
            "category         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution:\n",
            "category\n",
            " 1    15770\n",
            " 0    12644\n",
            "-1     8248\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Minority Class: -1 (Count: 8248)\n"
          ]
        }
      ],
      "source": [
        "class_counts = df['category'].value_counts()\n",
        "print(\"Class Distribution:\")\n",
        "print(class_counts)\n",
        "\n",
        "# The minority class is the one with the lowest count\n",
        "minority_class = class_counts.index[-1]\n",
        "minority_count = class_counts.min()\n",
        "\n",
        "print(f\"\\nMinority Class: {minority_class} (Count: {minority_count})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Experiment Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "run_experiment_function"
      },
      "outputs": [],
      "source": [
        "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
        "    \"\"\"Runs a single experiment, logs parameters and metrics to MLflow.\"\"\"\n",
        "    \n",
        "    # 1. Vectorizer Initialization\n",
        "    if vectorizer_type == \"BoW\":\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "\n",
        "    # 2. Data Split (Using original DataFrame to ensure consistent splitting)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], \n",
        "                                                              test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    # 3. Vectorization\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "    \n",
        "    # 4. MLflow Run\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", vectorizer_max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train_vec, y_train)\n",
        "\n",
        "        # 5. Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report details\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # 6. Log confusion matrix plot\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close() # Close plot to free memory\n",
        "\n",
        "        # 7. Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "\n",
        "        print(f\"Completed run: {vectorizer_name} with {ngram_range} n-gram range. Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Execute Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "execute_experiments"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running n-gram range: (1, 1) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 14:27:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 14:28:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed run: BoW with (1, 1) n-gram range. Accuracy: 0.6460\n",
            "üèÉ View run BoW_(1, 1)_RandomForest at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833/runs/b0897df6b2da45e6b73a2bd46ae3ed50\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 14:29:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 14:29:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed run: TF-IDF with (1, 1) n-gram range. Accuracy: 0.6443\n",
            "üèÉ View run TF-IDF_(1, 1)_RandomForest at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833/runs/dab936c124754c94b241a329291cfd07\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833\n",
            "\n",
            "--- Running n-gram range: (1, 2) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 14:30:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 14:31:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed run: BoW with (1, 2) n-gram range. Accuracy: 0.6486\n",
            "üèÉ View run BoW_(1, 2)_RandomForest at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833/runs/4782585b428741438797719ec431376b\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 14:32:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 14:32:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed run: TF-IDF with (1, 2) n-gram range. Accuracy: 0.6529\n",
            "üèÉ View run TF-IDF_(1, 2)_RandomForest at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833/runs/6418294871a045eda06b2effbbc788ae\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833\n",
            "\n",
            "--- Running n-gram range: (1, 3) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 14:33:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 14:33:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed run: BoW with (1, 3) n-gram range. Accuracy: 0.6469\n",
            "üèÉ View run BoW_(1, 3)_RandomForest at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833/runs/1fdc6c29eed2495abdcce7e308714084\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 14:35:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 14:35:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed run: TF-IDF with (1, 3) n-gram range. Accuracy: 0.6471\n",
            "üèÉ View run TF-IDF_(1, 3)_RandomForest at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833/runs/61cffb6d480240ebbf5933598b87e3ec\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/111723537539582833\n"
          ]
        }
      ],
      "source": [
        "# Define the experiment space\n",
        "ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # Unigrams, Bigrams, Trigrams\n",
        "max_features = 5000  # Limiting feature size for all experiments\n",
        "\n",
        "for ngram_range in ngram_ranges:\n",
        "    print(f\"\\n--- Running n-gram range: {ngram_range} ---\")\n",
        "    \n",
        "    # BoW Experiments\n",
        "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
        "\n",
        "    # TF-IDF Experiments\n",
        "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusion\n",
        "Review the results in the MLflow UI (using the tracking URI provided) to compare the performance metrics (accuracy, precision, recall, f1-score) logged for each combination of vectorizer type and n-gram range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Detailed Comparison of Feature Engineering Methods (Sorted by -1_F1-Score) ---\n",
            "| Vectorizer   | N-gram Range   |   Max Features |   Accuracy (Overall) |   -1_Precision |   -1_Recall |   -1_F1-Score | Run ID                           |\n",
            "|:-------------|:---------------|---------------:|---------------------:|---------------:|------------:|--------------:|:---------------------------------|\n",
            "| TF-IDF       | (1, 2)         |           5000 |               0.6529 |         0.9216 |      0.0285 |        0.0553 | 6418294871a045eda06b2effbbc788ae |\n",
            "| BoW          | (1, 2)         |           5000 |               0.6486 |         0.9737 |      0.0224 |        0.0438 | 4782585b428741438797719ec431376b |\n",
            "| TF-IDF       | (1, 3)         |           5000 |               0.6471 |         0.9714 |      0.0206 |        0.0404 | 61cffb6d480240ebbf5933598b87e3ec |\n",
            "| BoW          | (1, 3)         |           5000 |               0.6469 |         0.9643 |      0.0164 |        0.0322 | 1fdc6c29eed2495abdcce7e308714084 |\n",
            "| TF-IDF       | (1, 1)         |           5000 |               0.6443 |         0.9583 |      0.0139 |        0.0275 | dab936c124754c94b241a329291cfd07 |\n",
            "| BoW          | (1, 1)         |           5000 |               0.6460 |         0.9583 |      0.0139 |        0.0275 | b0897df6b2da45e6b73a2bd46ae3ed50 |\n",
            "\n",
            "================================================================================\n",
            "ü•á Best Feature Engineering Combination (Based on Minority Class F1-Score):\n",
            "Vectorizer: TF-IDF\n",
            "N-gram Range: (1, 2)\n",
            "Max Features: 5000\n",
            "F1-Score (Minority Class): 0.0553\n",
            "Rationale: This combination offers the best balance between Precision and Recall for the critical minority class, which is vital for effective comment moderation.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import ast # Needed to safely evaluate the string representation of the tuple from MLflow\n",
        "\n",
        "\n",
        "runs = mlflow.search_runs(\n",
        "    filter_string=\"tags.experiment_type = 'feature_engineering'\"\n",
        ")\n",
        "\n",
        "comparison_data = []\n",
        "\n",
        "# Iterate through the retrieved runs\n",
        "for _, run in runs.iterrows():\n",
        "    run_id = run['run_id']\n",
        "    \n",
        "    # Extract parameters\n",
        "    vectorizer_type = run['params.vectorizer_type']\n",
        "    vectorizer_max_features = run['params.vectorizer_max_features']\n",
        "    \n",
        "    # Safely convert the string tuple representation back to a tuple for labeling\n",
        "    ngram_range_str = run['params.ngram_range']\n",
        "    try:\n",
        "        # Use ast.literal_eval for safe conversion from string to tuple\n",
        "        ngram_range = ast.literal_eval(ngram_range_str)\n",
        "    except (ValueError, SyntaxError):\n",
        "        # Fallback if the string format is unexpected\n",
        "        ngram_range = ngram_range_str \n",
        "    \n",
        "    # Extract metrics\n",
        "    # Note: Using .get() ensures the script doesn't crash if a metric is missing, \n",
        "    # but since the experiment logs them all, they should be present.\n",
        "    row = {\n",
        "        'Vectorizer': vectorizer_type,\n",
        "        'N-gram Range': str(ngram_range),\n",
        "        'Max Features': vectorizer_max_features,\n",
        "        'Accuracy (Overall)': run['metrics.accuracy'],\n",
        "        # Metrics for the Minority Class (-1)\n",
        "        '-1_Precision': run.get('metrics.-1_precision', 0.0),\n",
        "        '-1_Recall': run.get('metrics.-1_recall', 0.0),\n",
        "        '-1_F1-Score': run.get('metrics.-1_f1-score', 0.0),\n",
        "        'Run ID': run_id\n",
        "    }\n",
        "    comparison_data.append(row)\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "\n",
        "df_comparison = df_comparison[['Vectorizer', 'N-gram Range', 'Max Features', 'Accuracy (Overall)', '-1_Precision', '-1_Recall', '-1_F1-Score', 'Run ID']]\n",
        "\n",
        "df_comparison = df_comparison.sort_values(by='-1_F1-Score', ascending=False)\n",
        "\n",
        "\n",
        "print(\"--- Detailed Comparison of Feature Engineering Methods (Sorted by -1_F1-Score) ---\")\n",
        "print(df_comparison.to_markdown(index=False, floatfmt=\".4f\"))\n",
        "\n",
        "if not df_comparison.empty:\n",
        "    best_method_row = df_comparison.iloc[0]\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ü•á Best Feature Engineering Combination (Based on Minority Class F1-Score):\")\n",
        "    print(f\"Vectorizer: {best_method_row['Vectorizer']}\")\n",
        "    print(f\"N-gram Range: {best_method_row['N-gram Range']}\")\n",
        "    print(f\"Max Features: {best_method_row['Max Features']}\")\n",
        "    print(f\"F1-Score (Minority Class): {best_method_row['-1_F1-Score']:.4f}\")\n",
        "    print(\"Rationale: This combination offers the best balance between Precision and Recall for the critical minority class, which is vital for effective comment moderation.\")\n",
        "    print(\"=\"*80)\n",
        "else:\n",
        "    print(\"\\nNo MLflow runs found for 'feature_engineering' experiment type.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìù Experiment Summary & Recommendations\n",
        "---\n",
        "\n",
        "#### ü•á Best Balanced Method\n",
        "- **Technique:** Undersampling  \n",
        "- **F1-Score (Minority Class):** 0.5257  \n",
        "- **Recall (Minority Class):** 0.4733  \n",
        "- **Rationale:** Undersampling provides the highest F1-Score (best balance between Precision and Recall), making it the most reliable technique for generalized comment analysis, minimizing both missed toxic comments and false alarms.\n",
        "\n",
        "---\n",
        "\n",
        "#### ü•á Best Feature Engineering Combination (Based on Minority Class F1-Score)\n",
        "- **Vectorizer:** TF-IDF  \n",
        "- **N-gram Range:** (1, 2)  \n",
        "- **Max Features:** 5000  \n",
        "- **F1-Score (Minority Class):** 0.0553  \n",
        "- **Rationale:** This combination offers the best balance between Precision and Recall for the critical minority class, which is vital for effective comment moderation.\n",
        "\"\"\"\n",
        "\n",
        "#### ü•á Optimal Feature Tuning (Based on Minority Class F1-Score)\n",
        "- **Vectorization Method:** TF-IDF Bigrams  \n",
        "- **Optimal Max Features:** 1000  \n",
        "- **F1-Score (Minority Class):** 0.2496  \n",
        "- **Rationale:** This feature count maximizes the model's ability to distinguish the critical minority class.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
