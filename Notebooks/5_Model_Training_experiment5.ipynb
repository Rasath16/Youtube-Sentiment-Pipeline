{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q optuna lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This experiment compares the performance of several classification algorithms (Logistic Regression, Naive Bayes, SVM, XGBoost, LightGBM). We apply Hyperparameter Tuning (HPT) to the complex models using Optuna, while fixing the feature engineering pipeline based on previous optimal choices:\n",
        "\n",
        "* **Vectorization:** TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "* **N-gram Range:** Bigram `(1, 2)` (Unigrams and Bigrams)\n",
        "* **Max Features:** 1000\n",
        "* **Imbalance Handling:** Undersampling (`RandomUnderSampler`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MLflow and Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 MLflow Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mlflow_config"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:30:59 INFO mlflow.tracking.fluent: Experiment with name 'Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://mlfow-bucket-2025/120831546946697659', creation_time=1765458058614, experiment_id='120831546946697659', last_update_time=1765458058614, lifecycle_stage='active', name='Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5', tags={}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the remote tracking server URI\n",
        "mlflow.set_tracking_uri(\"http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/\")\n",
        "\n",
        "# Set or create a new experiment\n",
        "mlflow.set_experiment(\"Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Data Loading, Remapping, and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (36662, 2)\n",
            "Class distribution:\n",
            "category\n",
            "0    12644\n",
            "1    15770\n",
            "2     8248\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Original Training Data Shape: (29329, 1000)\n",
            "Test Data Shape: (7333, 1000)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../data/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"Class distribution:\\n{df['category'].value_counts().sort_index()}\")\n",
        "\n",
        "# Fixed parameters\n",
        "ngram_range = (1, 2)\n",
        "max_features = 1000\n",
        "\n",
        "# Split and vectorize\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_comment'], df['category'], \n",
        "    test_size=0.2, random_state=42, stratify=df['category']\n",
        ")\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\nOriginal Training Data Shape: {X_train_vec.shape}\")\n",
        "print(f\"Test Data Shape: {X_test_vec.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resampled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CREATING 3 RESAMPLED DATASETS (TOP 3 IMBALANCE METHODS)\n",
            "================================================================================\n",
            "1. Undersampled: (19794, 1000)\n",
            "2. Oversampled: (37848, 1000)\n",
            "3. ADASYN: (35909, 1000)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING 3 RESAMPLED DATASETS (TOP 3 IMBALANCE METHODS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Method 1: Undersampling\n",
        "sampler_under = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = sampler_under.fit_resample(X_train_vec, y_train)\n",
        "print(f\"1. Undersampled: {X_train_under.shape}\")\n",
        "\n",
        "# Method 2: Oversampling\n",
        "sampler_over = RandomOverSampler(random_state=42)\n",
        "X_train_over, y_train_over = sampler_over.fit_resample(X_train_vec, y_train)\n",
        "print(f\"2. Oversampled: {X_train_over.shape}\")\n",
        "\n",
        "# Method 3: ADASYN\n",
        "sampler_adasyn = ADASYN(random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = sampler_adasyn.fit_resample(X_train_vec, y_train)\n",
        "print(f\"3. ADASYN: {X_train_adasyn.shape}\")\n",
        "\n",
        "# Store all datasets\n",
        "datasets = {\n",
        "    'undersampling': (X_train_under, y_train_under),\n",
        "    'oversampling': (X_train_over, y_train_over),\n",
        "    'adasyn': (X_train_adasyn, y_train_adasyn)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLflow Logging and Evaluation Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "log_mlflow_helper"
      },
      "outputs": [],
      "source": [
        "def log_mlflow(model_name, model, params=None, imbalance_method=\"undersampling\"):\n",
        "    with mlflow.start_run():\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_{imbalance_method}_TFIDF(1000)_HPT\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"multi_algo_hpt\")\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", str(ngram_range))\n",
        "        mlflow.log_param(\"max_features\", max_features)\n",
        "        mlflow.log_param(\"imbalance_handling\", imbalance_method)\n",
        "        \n",
        "        if params:\n",
        "            for key, value in params.items():\n",
        "                mlflow.log_param(key, value)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        # Log metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.title(f\"Confusion Matrix: {model_name} ({imbalance_method})\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.savefig(f\"conf_matrix_{model_name}_{imbalance_method}.png\")\n",
        "        mlflow.log_artifact(f\"conf_matrix_{model_name}_{imbalance_method}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "        \n",
        "        print(f\"    ‚úì Logged with Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Hyperparameter Tuning Objectives (Optuna)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "optuna_objectives"
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 10\n",
        "\n",
        "def tune_logistic_regression(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
        "        solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])\n",
        "        model = LogisticRegression(C=C, solver=solver, random_state=42, multi_class='auto', max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params\n",
        "\n",
        "def tune_linear_svc(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        C = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
        "        model = LinearSVC(C=C, random_state=42, max_iter=1000, dual='auto')\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params\n",
        "\n",
        "def tune_xgboost(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
        "        max_depth = trial.suggest_int('max_depth', 3, 7)\n",
        "        model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth,\n",
        "                             random_state=42, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params\n",
        "\n",
        "def tune_lightgbm(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
        "        num_leaves = trial.suggest_int('num_leaves', 10, 50)\n",
        "        model = LGBMClassifier(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves,\n",
        "                              random_state=42, verbose=-1)\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Execution and MLflow Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "execution_pipeline"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING MODEL TRAINING WITH ALL SAMPLING METHODS\n",
            "================================================================================\n",
            "Strategy: Train each algorithm on all 3 sampling methods separately\n",
            "This creates 12 models (4 algorithms √ó 3 sampling methods)\n",
            "MLflow will track all and identify the best combination\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "BASELINE: MultinomialNB (No HPT)\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:31:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:32:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7000\n",
            "üèÉ View run MultinomialNB_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/d168744c79bb45eca4eeb2b6e397b6ed\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:32:29,523] A new study created in memory with name: no-name-a141a419-c73f-4b59-aa7c-864c3b61892e\n",
            "[I 2025-12-11 18:32:29,586] Trial 0 finished with value: 0.6687576708032184 and parameters: {'C': 0.005483115775663099, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6687576708032184.\n",
            "[I 2025-12-11 18:32:29,637] Trial 1 finished with value: 0.6742124642029184 and parameters: {'C': 0.009550223105061338, 'solver': 'liblinear'}. Best is trial 1 with value: 0.6742124642029184.\n",
            "[I 2025-12-11 18:32:29,707] Trial 2 finished with value: 0.7404882040092732 and parameters: {'C': 0.14773286727600024, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7404882040092732.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING LogisticRegression ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:32:29,825] Trial 3 finished with value: 0.7455338879039957 and parameters: {'C': 0.12487814090553052, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.7455338879039957.\n",
            "[I 2025-12-11 18:32:29,920] Trial 4 finished with value: 0.7421246420291832 and parameters: {'C': 0.10494184839269742, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.7455338879039957.\n",
            "[I 2025-12-11 18:32:29,984] Trial 5 finished with value: 0.7278058093549706 and parameters: {'C': 0.05682541431745017, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.7455338879039957.\n",
            "[I 2025-12-11 18:32:30,019] Trial 6 finished with value: 0.6661666439383608 and parameters: {'C': 0.002823059023703137, 'solver': 'liblinear'}. Best is trial 3 with value: 0.7455338879039957.\n",
            "[I 2025-12-11 18:32:30,083] Trial 7 finished with value: 0.7363971089594982 and parameters: {'C': 0.1224960970059363, 'solver': 'liblinear'}. Best is trial 3 with value: 0.7455338879039957.\n",
            "[I 2025-12-11 18:32:30,194] Trial 8 finished with value: 0.7809900450020455 and parameters: {'C': 2.1653073230109707, 'solver': 'liblinear'}. Best is trial 8 with value: 0.7809900450020455.\n",
            "[I 2025-12-11 18:32:30,257] Trial 9 finished with value: 0.6892131460520933 and parameters: {'C': 0.019436867318008734, 'solver': 'liblinear'}. Best is trial 8 with value: 0.7809900450020455.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 2.1653073230109707, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:32:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:33:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7810\n",
            "üèÉ View run LogisticRegression_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/9115e563a1f04d14b5776489d830fc46\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:33:19,841] A new study created in memory with name: no-name-89622f93-5a3d-40a4-861c-f32396a38a7e\n",
            "[I 2025-12-11 18:33:19,927] Trial 0 finished with value: 0.6649393154234283 and parameters: {'C': 0.0014108107026286978, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.6649393154234283.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:33:20,354] Trial 1 finished with value: 0.7820810036819855 and parameters: {'C': 2.643463618683302, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:20,628] Trial 2 finished with value: 0.7818082640120005 and parameters: {'C': 0.742975414137399, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:20,794] Trial 3 finished with value: 0.7190781399154507 and parameters: {'C': 0.028605525069124667, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:21,184] Trial 4 finished with value: 0.7809900450020455 and parameters: {'C': 7.726726117027922, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:21,308] Trial 5 finished with value: 0.6988954043365607 and parameters: {'C': 0.014880547063656192, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:21,468] Trial 6 finished with value: 0.7166234828855857 and parameters: {'C': 0.025916504269451465, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:21,580] Trial 7 finished with value: 0.7138960861857357 and parameters: {'C': 0.016027581120989974, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:21,708] Trial 8 finished with value: 0.6986226646665757 and parameters: {'C': 0.010225593918551136, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7820810036819855.\n",
            "[I 2025-12-11 18:33:22,092] Trial 9 finished with value: 0.781126414837038 and parameters: {'C': 5.440388277960527, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7820810036819855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 2.643463618683302, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:33:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:34:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7821\n",
            "üèÉ View run LogisticRegression_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/698664d76c8f40929640e38afee765e0\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:34:13,952] A new study created in memory with name: no-name-39af08d5-ac05-4b3d-bc94-7846a8227631\n",
            "[I 2025-12-11 18:34:14,098] Trial 0 finished with value: 0.6946679394517933 and parameters: {'C': 0.012283267524728244, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.6946679394517933.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:34:14,390] Trial 1 finished with value: 0.7741715532524206 and parameters: {'C': 2.675201296086194, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:14,529] Trial 2 finished with value: 0.6309832265102959 and parameters: {'C': 0.0059198868479968135, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:14,755] Trial 3 finished with value: 0.7443065593890631 and parameters: {'C': 0.07202060786835728, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:15,317] Trial 4 finished with value: 0.7718532660575481 and parameters: {'C': 3.6607733308810486, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:15,568] Trial 5 finished with value: 0.7650347743079231 and parameters: {'C': 0.4886378996214002, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:15,670] Trial 6 finished with value: 0.6709395881630983 and parameters: {'C': 0.006877360505435292, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:16,034] Trial 7 finished with value: 0.7642165552979681 and parameters: {'C': 0.37632041183135756, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:16,126] Trial 8 finished with value: 0.49474976135278875 and parameters: {'C': 0.001591668432032344, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 18:34:16,663] Trial 9 finished with value: 0.7674894313377881 and parameters: {'C': 1.3448477568173, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7741715532524206.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 2.675201296086194, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:34:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:35:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7742\n",
            "üèÉ View run LogisticRegression_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/0401370285cf47c392245c782119333d\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:35:07,107] A new study created in memory with name: no-name-9cd5a082-a3c1-46cf-8c0b-3af45ac936ba\n",
            "[I 2025-12-11 18:35:07,265] Trial 0 finished with value: 0.783035592526933 and parameters: {'C': 1.133325557667224}. Best is trial 0 with value: 0.783035592526933.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING LinearSVC ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:35:07,423] Trial 1 finished with value: 0.7831719623619255 and parameters: {'C': 1.2346461001601727}. Best is trial 1 with value: 0.7831719623619255.\n",
            "[I 2025-12-11 18:35:07,584] Trial 2 finished with value: 0.7835810718669031 and parameters: {'C': 1.9104955545783033}. Best is trial 2 with value: 0.7835810718669031.\n",
            "[I 2025-12-11 18:35:07,728] Trial 3 finished with value: 0.7834447020319105 and parameters: {'C': 1.598854139519303}. Best is trial 2 with value: 0.7835810718669031.\n",
            "[I 2025-12-11 18:35:07,907] Trial 4 finished with value: 0.7839901813718806 and parameters: {'C': 3.565030152983778}. Best is trial 4 with value: 0.7839901813718806.\n",
            "[I 2025-12-11 18:35:08,035] Trial 5 finished with value: 0.7849447702168281 and parameters: {'C': 0.4344550210538833}. Best is trial 5 with value: 0.7849447702168281.\n",
            "[I 2025-12-11 18:35:08,132] Trial 6 finished with value: 0.7805809354970681 and parameters: {'C': 0.14563936837104702}. Best is trial 5 with value: 0.7849447702168281.\n",
            "[I 2025-12-11 18:35:08,377] Trial 7 finished with value: 0.7828992226919406 and parameters: {'C': 7.9202384503551615}. Best is trial 5 with value: 0.7849447702168281.\n",
            "[I 2025-12-11 18:35:08,511] Trial 8 finished with value: 0.7831719623619255 and parameters: {'C': 0.7401649312272338}. Best is trial 5 with value: 0.7849447702168281.\n",
            "[I 2025-12-11 18:35:08,711] Trial 9 finished with value: 0.7839901813718806 and parameters: {'C': 2.902659417229207}. Best is trial 5 with value: 0.7849447702168281.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 0.4344550210538833}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:35:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:35:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7849\n",
            "üèÉ View run LinearSVC_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/47b99e9414b747adba0a4f74e0852bfc\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:35:56,620] A new study created in memory with name: no-name-83f0a13d-6bd2-4247-b016-c95546525a04\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:35:57,047] Trial 0 finished with value: 0.7856266193917906 and parameters: {'C': 1.5018954478935285}. Best is trial 0 with value: 0.7856266193917906.\n",
            "[I 2025-12-11 18:35:57,531] Trial 1 finished with value: 0.785217509886813 and parameters: {'C': 4.277625839518987}. Best is trial 0 with value: 0.7856266193917906.\n",
            "[I 2025-12-11 18:35:57,762] Trial 2 finished with value: 0.7842629210418656 and parameters: {'C': 0.123376269083637}. Best is trial 0 with value: 0.7856266193917906.\n",
            "[I 2025-12-11 18:35:58,266] Trial 3 finished with value: 0.785217509886813 and parameters: {'C': 4.769428383397109}. Best is trial 0 with value: 0.7856266193917906.\n",
            "[I 2025-12-11 18:35:58,692] Trial 4 finished with value: 0.7858993590617755 and parameters: {'C': 1.177671774968524}. Best is trial 4 with value: 0.7858993590617755.\n",
            "[I 2025-12-11 18:35:58,982] Trial 5 finished with value: 0.7846720305468431 and parameters: {'C': 0.4193869483671542}. Best is trial 4 with value: 0.7858993590617755.\n",
            "[I 2025-12-11 18:35:59,389] Trial 6 finished with value: 0.7856266193917906 and parameters: {'C': 1.7467906266824178}. Best is trial 4 with value: 0.7858993590617755.\n",
            "[I 2025-12-11 18:35:59,748] Trial 7 finished with value: 0.7846720305468431 and parameters: {'C': 0.4022563157784878}. Best is trial 4 with value: 0.7858993590617755.\n",
            "[I 2025-12-11 18:36:00,210] Trial 8 finished with value: 0.785762989226783 and parameters: {'C': 1.3824119772867147}. Best is trial 4 with value: 0.7858993590617755.\n",
            "[I 2025-12-11 18:36:00,901] Trial 9 finished with value: 0.7850811400518205 and parameters: {'C': 8.712987434699041}. Best is trial 4 with value: 0.7858993590617755.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 1.177671774968524}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:36:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:36:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7859\n",
            "üèÉ View run LinearSVC_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/4a876f32e32d4f2bb2fd9401a1af2778\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:36:48,258] A new study created in memory with name: no-name-fe753b54-cf5f-42af-88bf-429a6bc21cd5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:36:48,829] Trial 0 finished with value: 0.7782626483021956 and parameters: {'C': 1.9927007662852156}. Best is trial 0 with value: 0.7782626483021956.\n",
            "[I 2025-12-11 18:36:49,484] Trial 1 finished with value: 0.7792172371471431 and parameters: {'C': 4.13333693298873}. Best is trial 1 with value: 0.7792172371471431.\n",
            "[I 2025-12-11 18:36:49,962] Trial 2 finished with value: 0.7785353879721806 and parameters: {'C': 2.0276751766581005}. Best is trial 1 with value: 0.7792172371471431.\n",
            "[I 2025-12-11 18:36:50,722] Trial 3 finished with value: 0.7785353879721806 and parameters: {'C': 2.4566861766079104}. Best is trial 1 with value: 0.7792172371471431.\n",
            "[I 2025-12-11 18:36:51,275] Trial 4 finished with value: 0.7788081276421656 and parameters: {'C': 3.4916185394595476}. Best is trial 1 with value: 0.7792172371471431.\n",
            "[I 2025-12-11 18:36:51,525] Trial 5 finished with value: 0.7751261420973681 and parameters: {'C': 0.1765121910052164}. Best is trial 1 with value: 0.7792172371471431.\n",
            "[I 2025-12-11 18:36:52,050] Trial 6 finished with value: 0.7793536069821355 and parameters: {'C': 4.527837909454349}. Best is trial 6 with value: 0.7793536069821355.\n",
            "[I 2025-12-11 18:36:52,578] Trial 7 finished with value: 0.7796263466521206 and parameters: {'C': 7.292693025205307}. Best is trial 7 with value: 0.7796263466521206.\n",
            "[I 2025-12-11 18:36:53,012] Trial 8 finished with value: 0.7785353879721806 and parameters: {'C': 2.0441545422088225}. Best is trial 7 with value: 0.7796263466521206.\n",
            "[I 2025-12-11 18:36:53,421] Trial 9 finished with value: 0.7778535387972181 and parameters: {'C': 0.7640461187961469}. Best is trial 7 with value: 0.7796263466521206.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 7.292693025205307}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:37:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:37:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7796\n",
            "üèÉ View run LinearSVC_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/819224f866eb48b69b61ac283839a525\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:37:43,696] A new study created in memory with name: no-name-8851ae05-c244-467a-a935-045d321653a7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING XGBoost ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:37:49,832] Trial 0 finished with value: 0.5105686622119188 and parameters: {'n_estimators': 96, 'learning_rate': 0.001318301118772021, 'max_depth': 3}. Best is trial 0 with value: 0.5105686622119188.\n",
            "[I 2025-12-11 18:38:27,613] Trial 1 finished with value: 0.7374880676394382 and parameters: {'n_estimators': 148, 'learning_rate': 0.06946333259232494, 'max_depth': 7}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:38:50,843] Trial 2 finished with value: 0.605345697531706 and parameters: {'n_estimators': 79, 'learning_rate': 0.007595395527123069, 'max_depth': 7}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:39:13,993] Trial 3 finished with value: 0.6103913814264285 and parameters: {'n_estimators': 65, 'learning_rate': 0.012491313805561972, 'max_depth': 7}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:39:23,620] Trial 4 finished with value: 0.5559798172644211 and parameters: {'n_estimators': 54, 'learning_rate': 0.0026862244139031323, 'max_depth': 5}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:39:49,123] Trial 5 finished with value: 0.6694395199781809 and parameters: {'n_estimators': 155, 'learning_rate': 0.02720852933281093, 'max_depth': 5}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:39:57,626] Trial 6 finished with value: 0.6856675303422883 and parameters: {'n_estimators': 81, 'learning_rate': 0.08846875842590916, 'max_depth': 4}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:40:13,028] Trial 7 finished with value: 0.5700259102686486 and parameters: {'n_estimators': 59, 'learning_rate': 0.0013906405349951682, 'max_depth': 6}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:41:01,119] Trial 8 finished with value: 0.6129824082912859 and parameters: {'n_estimators': 199, 'learning_rate': 0.00571277678958172, 'max_depth': 6}. Best is trial 1 with value: 0.7374880676394382.\n",
            "[I 2025-12-11 18:41:14,652] Trial 9 finished with value: 0.5711168689485886 and parameters: {'n_estimators': 80, 'learning_rate': 0.006538617660315783, 'max_depth': 5}. Best is trial 1 with value: 0.7374880676394382.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 148, 'learning_rate': 0.06946333259232494, 'max_depth': 7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:42:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:42:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7375\n",
            "üèÉ View run XGBoost_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/dd69b4f8321f45c59139bf124232ff7a\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:42:47,817] A new study created in memory with name: no-name-9c0d7290-9db9-4be3-982a-2607b5861abd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:43:02,077] Trial 0 finished with value: 0.5859811809627711 and parameters: {'n_estimators': 89, 'learning_rate': 0.012118973021886328, 'max_depth': 4}. Best is trial 0 with value: 0.5859811809627711.\n",
            "[I 2025-12-11 18:44:20,177] Trial 1 finished with value: 0.7265784808400382 and parameters: {'n_estimators': 176, 'learning_rate': 0.04101989822527027, 'max_depth': 7}. Best is trial 1 with value: 0.7265784808400382.\n",
            "[I 2025-12-11 18:44:28,016] Trial 2 finished with value: 0.5160234556116187 and parameters: {'n_estimators': 67, 'learning_rate': 0.0044010780976561645, 'max_depth': 3}. Best is trial 1 with value: 0.7265784808400382.\n",
            "[I 2025-12-11 18:45:02,983] Trial 3 finished with value: 0.5563889267693987 and parameters: {'n_estimators': 80, 'learning_rate': 0.0010293010196797366, 'max_depth': 6}. Best is trial 1 with value: 0.7265784808400382.\n",
            "[I 2025-12-11 18:45:53,500] Trial 4 finished with value: 0.7428064912041457 and parameters: {'n_estimators': 111, 'learning_rate': 0.09321739378249722, 'max_depth': 7}. Best is trial 4 with value: 0.7428064912041457.\n",
            "[I 2025-12-11 18:46:07,768] Trial 5 finished with value: 0.5322514659757261 and parameters: {'n_estimators': 127, 'learning_rate': 0.004170034795730477, 'max_depth': 3}. Best is trial 4 with value: 0.7428064912041457.\n",
            "[I 2025-12-11 18:46:18,251] Trial 6 finished with value: 0.6724396563480158 and parameters: {'n_estimators': 56, 'learning_rate': 0.09177638811117357, 'max_depth': 4}. Best is trial 4 with value: 0.7428064912041457.\n",
            "[I 2025-12-11 18:46:56,127] Trial 7 finished with value: 0.605618437201691 and parameters: {'n_estimators': 84, 'learning_rate': 0.010498335405226484, 'max_depth': 6}. Best is trial 4 with value: 0.7428064912041457.\n",
            "[I 2025-12-11 18:47:24,377] Trial 8 finished with value: 0.6866221191872358 and parameters: {'n_estimators': 106, 'learning_rate': 0.04611205375136715, 'max_depth': 5}. Best is trial 4 with value: 0.7428064912041457.\n",
            "[I 2025-12-11 18:47:49,000] Trial 9 finished with value: 0.5653893358789036 and parameters: {'n_estimators': 56, 'learning_rate': 0.002803731330620121, 'max_depth': 6}. Best is trial 4 with value: 0.7428064912041457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 111, 'learning_rate': 0.09321739378249722, 'max_depth': 7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:49:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:49:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7428\n",
            "üèÉ View run XGBoost_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/e4496076a7524ea4ac3435b6bd401a7d\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:49:34,999] A new study created in memory with name: no-name-73d33038-de7f-4a9d-87e7-05a895022568\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:50:09,342] Trial 0 finished with value: 0.6436656211645984 and parameters: {'n_estimators': 180, 'learning_rate': 0.013942850267303656, 'max_depth': 4}. Best is trial 0 with value: 0.6436656211645984.\n",
            "[I 2025-12-11 18:50:38,406] Trial 1 finished with value: 0.6315287058502659 and parameters: {'n_estimators': 58, 'learning_rate': 0.018815131774211638, 'max_depth': 6}. Best is trial 0 with value: 0.6436656211645984.\n",
            "[I 2025-12-11 18:51:18,050] Trial 2 finished with value: 0.5557070775944362 and parameters: {'n_estimators': 186, 'learning_rate': 0.0015973589890464592, 'max_depth': 4}. Best is trial 0 with value: 0.6436656211645984.\n",
            "[I 2025-12-11 18:52:23,920] Trial 3 finished with value: 0.565525705713896 and parameters: {'n_estimators': 196, 'learning_rate': 0.0018753844942454535, 'max_depth': 5}. Best is trial 0 with value: 0.6436656211645984.\n",
            "[I 2025-12-11 18:53:47,840] Trial 4 finished with value: 0.6736669848629483 and parameters: {'n_estimators': 181, 'learning_rate': 0.016408474219023028, 'max_depth': 6}. Best is trial 4 with value: 0.6736669848629483.\n",
            "[I 2025-12-11 18:54:26,717] Trial 5 finished with value: 0.5559798172644211 and parameters: {'n_estimators': 117, 'learning_rate': 0.0016022794071445092, 'max_depth': 5}. Best is trial 4 with value: 0.6736669848629483.\n",
            "[I 2025-12-11 18:55:01,543] Trial 6 finished with value: 0.7130778671757807 and parameters: {'n_estimators': 54, 'learning_rate': 0.09558195759031882, 'max_depth': 7}. Best is trial 6 with value: 0.7130778671757807.\n",
            "[I 2025-12-11 18:55:36,524] Trial 7 finished with value: 0.5559798172644211 and parameters: {'n_estimators': 104, 'learning_rate': 0.0017471298689959564, 'max_depth': 5}. Best is trial 6 with value: 0.7130778671757807.\n",
            "[I 2025-12-11 18:56:23,829] Trial 8 finished with value: 0.6845765716623483 and parameters: {'n_estimators': 106, 'learning_rate': 0.039947641141295315, 'max_depth': 6}. Best is trial 6 with value: 0.7130778671757807.\n",
            "[I 2025-12-11 18:57:14,555] Trial 9 finished with value: 0.6480294558843583 and parameters: {'n_estimators': 74, 'learning_rate': 0.01911721553918675, 'max_depth': 7}. Best is trial 6 with value: 0.7130778671757807.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 54, 'learning_rate': 0.09558195759031882, 'max_depth': 7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:58:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 18:58:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7131\n",
            "üèÉ View run XGBoost_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/f37abc4edd35448cb038c06e2943f9f3\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:58:43,561] A new study created in memory with name: no-name-6f406df8-9dc8-462b-b775-3bcad3f9c8fd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING LightGBM ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 18:58:45,725] Trial 0 finished with value: 0.600981862811946 and parameters: {'n_estimators': 101, 'learning_rate': 0.002340225615337289, 'num_leaves': 10}. Best is trial 0 with value: 0.600981862811946.\n",
            "[I 2025-12-11 18:58:53,002] Trial 1 finished with value: 0.7815355243420156 and parameters: {'n_estimators': 151, 'learning_rate': 0.07012188878384279, 'num_leaves': 36}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:58:55,329] Trial 2 finished with value: 0.7443065593890631 and parameters: {'n_estimators': 84, 'learning_rate': 0.04694998201599227, 'num_leaves': 17}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:58:57,698] Trial 3 finished with value: 0.7650347743079231 and parameters: {'n_estimators': 72, 'learning_rate': 0.07667283937068846, 'num_leaves': 19}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:59:04,528] Trial 4 finished with value: 0.781126414837038 and parameters: {'n_estimators': 110, 'learning_rate': 0.09693195594515351, 'num_leaves': 46}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:59:07,440] Trial 5 finished with value: 0.6650756852584209 and parameters: {'n_estimators': 81, 'learning_rate': 0.005563165634590744, 'num_leaves': 16}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:59:11,607] Trial 6 finished with value: 0.7268512205100232 and parameters: {'n_estimators': 102, 'learning_rate': 0.01695167706695456, 'num_leaves': 22}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:59:18,338] Trial 7 finished with value: 0.7234419746352106 and parameters: {'n_estimators': 154, 'learning_rate': 0.009178137804451755, 'num_leaves': 24}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:59:23,048] Trial 8 finished with value: 0.7430792308741306 and parameters: {'n_estimators': 65, 'learning_rate': 0.009022376247133446, 'num_leaves': 47}. Best is trial 1 with value: 0.7815355243420156.\n",
            "[I 2025-12-11 18:59:25,423] Trial 9 finished with value: 0.7413064230192281 and parameters: {'n_estimators': 97, 'learning_rate': 0.06505790604779327, 'num_leaves': 10}. Best is trial 1 with value: 0.7815355243420156.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 151, 'learning_rate': 0.07012188878384279, 'num_leaves': 36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 18:59:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 19:00:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7815\n",
            "üèÉ View run LightGBM_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/f9ff6466cecd40c3ba83c8acb028ace6\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 19:00:38,907] A new study created in memory with name: no-name-1583c0e0-5a09-448a-9a09-9626b82edc5c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 19:00:48,650] Trial 0 finished with value: 0.790126823946543 and parameters: {'n_estimators': 168, 'learning_rate': 0.0869345833365426, 'num_leaves': 23}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:01:08,113] Trial 1 finished with value: 0.7867175780717305 and parameters: {'n_estimators': 193, 'learning_rate': 0.09964924184743591, 'num_leaves': 48}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:01:24,505] Trial 2 finished with value: 0.778671757807173 and parameters: {'n_estimators': 137, 'learning_rate': 0.02319395090836669, 'num_leaves': 48}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:01:34,944] Trial 3 finished with value: 0.7303968362198282 and parameters: {'n_estimators': 129, 'learning_rate': 0.00897887900602612, 'num_leaves': 30}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:01:41,643] Trial 4 finished with value: 0.7633983362880131 and parameters: {'n_estimators': 82, 'learning_rate': 0.03665724416766727, 'num_leaves': 30}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:01:59,720] Trial 5 finished with value: 0.7377608073094232 and parameters: {'n_estimators': 135, 'learning_rate': 0.002511426186980928, 'num_leaves': 46}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:02:23,016] Trial 6 finished with value: 0.7398063548343107 and parameters: {'n_estimators': 167, 'learning_rate': 0.001672908164558826, 'num_leaves': 48}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:02:40,145] Trial 7 finished with value: 0.7823537433519705 and parameters: {'n_estimators': 118, 'learning_rate': 0.04040978802532641, 'num_leaves': 41}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:02:53,212] Trial 8 finished with value: 0.6787126687576708 and parameters: {'n_estimators': 175, 'learning_rate': 0.0019205142431797675, 'num_leaves': 21}. Best is trial 0 with value: 0.790126823946543.\n",
            "[I 2025-12-11 19:02:59,789] Trial 9 finished with value: 0.7168962225555707 and parameters: {'n_estimators': 77, 'learning_rate': 0.015079256828702717, 'num_leaves': 24}. Best is trial 0 with value: 0.790126823946543.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 168, 'learning_rate': 0.0869345833365426, 'num_leaves': 23}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 19:03:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 19:04:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7901\n",
            "üèÉ View run LightGBM_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/bc846ad7390b4960a4cfaa0783a70bda\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 19:04:14,867] A new study created in memory with name: no-name-6ea81106-e35d-4f2a-bfb0-f877dfd59de2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 19:04:24,450] Trial 0 finished with value: 0.7054411564162008 and parameters: {'n_estimators': 104, 'learning_rate': 0.0012928930714582298, 'num_leaves': 28}. Best is trial 0 with value: 0.7054411564162008.\n",
            "[I 2025-12-11 19:04:29,015] Trial 1 finished with value: 0.771307786717578 and parameters: {'n_estimators': 87, 'learning_rate': 0.06575695372532099, 'num_leaves': 17}. Best is trial 1 with value: 0.771307786717578.\n",
            "[I 2025-12-11 19:04:33,139] Trial 2 finished with value: 0.6694395199781809 and parameters: {'n_estimators': 67, 'learning_rate': 0.002584842410186994, 'num_leaves': 16}. Best is trial 1 with value: 0.771307786717578.\n",
            "[I 2025-12-11 19:04:44,067] Trial 3 finished with value: 0.7478521750988681 and parameters: {'n_estimators': 77, 'learning_rate': 0.005900864771285144, 'num_leaves': 50}. Best is trial 1 with value: 0.771307786717578.\n",
            "[I 2025-12-11 19:04:58,196] Trial 4 finished with value: 0.7148506750306832 and parameters: {'n_estimators': 151, 'learning_rate': 0.0019958278185776583, 'num_leaves': 31}. Best is trial 1 with value: 0.771307786717578.\n",
            "[I 2025-12-11 19:05:09,287] Trial 5 finished with value: 0.7546706668484932 and parameters: {'n_estimators': 72, 'learning_rate': 0.018700116638433142, 'num_leaves': 43}. Best is trial 1 with value: 0.771307786717578.\n",
            "[I 2025-12-11 19:05:13,517] Trial 6 finished with value: 0.7741715532524206 and parameters: {'n_estimators': 79, 'learning_rate': 0.08980961188201096, 'num_leaves': 15}. Best is trial 6 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 19:05:26,103] Trial 7 finished with value: 0.7117141688258557 and parameters: {'n_estimators': 151, 'learning_rate': 0.0010262038965861908, 'num_leaves': 27}. Best is trial 6 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 19:05:29,611] Trial 8 finished with value: 0.7096686213009682 and parameters: {'n_estimators': 94, 'learning_rate': 0.03695527503862288, 'num_leaves': 10}. Best is trial 6 with value: 0.7741715532524206.\n",
            "[I 2025-12-11 19:05:37,248] Trial 9 finished with value: 0.7342151915996181 and parameters: {'n_estimators': 83, 'learning_rate': 0.013963497881950627, 'num_leaves': 31}. Best is trial 6 with value: 0.7741715532524206.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 79, 'learning_rate': 0.08980961188201096, 'num_leaves': 15}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/11 19:06:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/11 19:06:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7742\n",
            "üèÉ View run LightGBM_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659/runs/3daa031883e24884b8011f4db9ed0efe\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/120831546946697659\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "‚úì ALL MODELS TRAINED AND LOGGED\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def train_individual_models_with_hpt(model_name, tune_func):\n",
        "    \"\"\"\n",
        "    Train separate models on each resampling method and log each one.\n",
        "    This allows us to find which algorithm + sampling method combination works best.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TRAINING {model_name} ON ALL 3 SAMPLING METHODS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    for method, (X_resample, y_resample) in datasets.items():\n",
        "        print(f\"\\n  [{method.upper()}] Running HPT ({N_TRIALS} trials)...\")\n",
        "        \n",
        "        # Tune hyperparameters\n",
        "        best_params = tune_func(X_resample, y_resample)\n",
        "        print(f\"    Best params: {best_params}\")\n",
        "        \n",
        "        # Train model with best params\n",
        "        if model_name == 'LogisticRegression':\n",
        "            model = LogisticRegression(random_state=42, multi_class='auto', max_iter=1000, **best_params)\n",
        "        elif model_name == 'LinearSVC':\n",
        "            model = LinearSVC(random_state=42, max_iter=1000, dual='auto', **best_params)\n",
        "        elif model_name == 'XGBoost':\n",
        "            model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1, **best_params)\n",
        "        elif model_name == 'LightGBM':\n",
        "            model = LGBMClassifier(random_state=42, verbose=-1, **best_params)\n",
        "        \n",
        "        model.fit(X_resample, y_resample)\n",
        "        \n",
        "        # Log each model separately\n",
        "        log_mlflow(f\"{model_name}\", model, params=best_params, imbalance_method=method)\n",
        "    \n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "# Execute Training\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING MODEL TRAINING WITH ALL SAMPLING METHODS\")\n",
        "print(\"=\"*80)\n",
        "print(\"Strategy: Train each algorithm on all 3 sampling methods separately\")\n",
        "print(\"This creates 12 models (4 algorithms √ó 3 sampling methods)\")\n",
        "print(\"MLflow will track all and identify the best combination\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Train baseline\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"BASELINE: MultinomialNB (No HPT)\")\n",
        "print(f\"{'='*80}\")\n",
        "mnb = MultinomialNB(alpha=1.0)\n",
        "mnb.fit(X_train_under, y_train_under)\n",
        "log_mlflow('MultinomialNB', mnb, params={'alpha': 1.0}, imbalance_method='undersampling')\n",
        "\n",
        "# Train all models on all sampling methods individually\n",
        "models_to_tune = [\n",
        "    ('LogisticRegression', tune_logistic_regression),\n",
        "    ('LinearSVC', tune_linear_svc),\n",
        "    ('XGBoost', tune_xgboost),\n",
        "    ('LightGBM', tune_lightgbm)\n",
        "]\n",
        "\n",
        "for model_name, tune_func in models_to_tune:\n",
        "    train_individual_models_with_hpt(model_name, tune_func)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úì ALL MODELS TRAINED AND LOGGED\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusion and Next Steps\n",
        "The complete set of model performances, including optimized hyperparameters, is now logged in the MLflow UI. The next step is typically stacking or selecting the single best performing model based on comprehensive evaluation metrics, especially F1-scores for the minority classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FETCHING RESULTS FROM EXPERIMENT\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TOP 10 MODELS (Sorted by Composite Score: Avg of Accuracy & Weighted F1)\n",
            "================================================================================\n",
            "         algo_name imbalance_handling  accuracy  weighted_f1  composite_score     2_f1\n",
            "          LightGBM       oversampling  0.790127     0.787081         0.788604 0.657987\n",
            "         LinearSVC       oversampling  0.785899     0.783413         0.784656 0.662285\n",
            "         LinearSVC      undersampling  0.784945     0.782788         0.783867 0.666874\n",
            "LogisticRegression       oversampling  0.782081     0.780060         0.781071 0.657169\n",
            "          LightGBM      undersampling  0.781536     0.779756         0.780646 0.657283\n",
            "LogisticRegression      undersampling  0.780990     0.779356         0.780173 0.659314\n",
            "         LinearSVC             adasyn  0.779626     0.777590         0.778608 0.643982\n",
            "LogisticRegression             adasyn  0.774172     0.773069         0.773621 0.635243\n",
            "          LightGBM             adasyn  0.774172     0.770442         0.772307 0.650081\n",
            "           XGBoost       oversampling  0.742806     0.739291         0.741049 0.617702\n",
            "\n",
            "================================================================================\n",
            "RANKINGS BY DIFFERENT METRICS\n",
            "================================================================================\n",
            "\n",
            "üìä Top 5 by Accuracy:\n",
            "  LightGBM                  (oversampling   ) - Accuracy: 0.7901\n",
            "  LinearSVC                 (oversampling   ) - Accuracy: 0.7859\n",
            "  LinearSVC                 (undersampling  ) - Accuracy: 0.7849\n",
            "  LogisticRegression        (oversampling   ) - Accuracy: 0.7821\n",
            "  LightGBM                  (undersampling  ) - Accuracy: 0.7815\n",
            "\n",
            "üìä Top 5 by Weighted F1-Score:\n",
            "  LightGBM                  (oversampling   ) - Weighted F1: 0.7871\n",
            "  LinearSVC                 (oversampling   ) - Weighted F1: 0.7834\n",
            "  LinearSVC                 (undersampling  ) - Weighted F1: 0.7828\n",
            "  LogisticRegression        (oversampling   ) - Weighted F1: 0.7801\n",
            "  LightGBM                  (undersampling  ) - Weighted F1: 0.7798\n",
            "\n",
            "üìä Top 5 by Minority Class (2) F1-Score:\n",
            "  LinearSVC                 (undersampling  ) - Class 2 F1: 0.6669\n",
            "  LinearSVC                 (oversampling   ) - Class 2 F1: 0.6623\n",
            "  LogisticRegression        (undersampling  ) - Class 2 F1: 0.6593\n",
            "  LightGBM                  (oversampling   ) - Class 2 F1: 0.6580\n",
            "  LightGBM                  (undersampling  ) - Class 2 F1: 0.6573\n",
            "\n",
            "================================================================================\n",
            "BEST SAMPLING METHOD FOR EACH ALGORITHM\n",
            "================================================================================\n",
            "\n",
            "LightGBM:\n",
            "  Best Sampling: oversampling\n",
            "  Accuracy: 0.7901\n",
            "  Weighted F1: 0.7871\n",
            "  Minority F1: 0.6580\n",
            "\n",
            "LinearSVC:\n",
            "  Best Sampling: oversampling\n",
            "  Accuracy: 0.7859\n",
            "  Weighted F1: 0.7834\n",
            "  Minority F1: 0.6623\n",
            "\n",
            "LogisticRegression:\n",
            "  Best Sampling: oversampling\n",
            "  Accuracy: 0.7821\n",
            "  Weighted F1: 0.7801\n",
            "  Minority F1: 0.6572\n",
            "\n",
            "XGBoost:\n",
            "  Best Sampling: oversampling\n",
            "  Accuracy: 0.7428\n",
            "  Weighted F1: 0.7393\n",
            "  Minority F1: 0.6177\n",
            "\n",
            "MultinomialNB:\n",
            "  Best Sampling: undersampling\n",
            "  Accuracy: 0.7000\n",
            "  Weighted F1: 0.7039\n",
            "  Minority F1: 0.5917\n",
            "\n",
            "================================================================================\n",
            "üèÜ BEST OVERALL MODEL (by Composite Score)\n",
            "================================================================================\n",
            "Algorithm: LightGBM\n",
            "Imbalance Handling: oversampling\n",
            "Composite Score: 0.7886\n",
            "Accuracy: 0.7901\n",
            "Weighted F1-Score: 0.7871\n",
            "Class 0 F1: 0.8431\n",
            "Class 1 F1: 0.8097\n",
            "Class 2 (Minority) F1: 0.6580\n",
            "Run ID: bc846ad7390b4960a4cfaa0783a70bda\n",
            "================================================================================\n",
            "\n",
            "üí° Key Insights:\n",
            "   ‚úì Each algorithm trained on undersampling, oversampling, and ADASYN\n",
            "   ‚úì Best model selected from all 12 combinations (4 algos √ó 3 methods)\n",
            "   ‚úì Composite Score balances accuracy with class-wise F1 performance\n",
            "   ‚úì This approach avoids ensemble voting that may reduce performance\n"
          ]
        }
      ],
      "source": [
        "OPTIMAL_METRIC = \"weighted avg_f1-score\"\n",
        "\n",
        "try:\n",
        "    client = mlflow.tracking.MlflowClient()\n",
        "    experiment = client.get_experiment_by_name(\"Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5\")\n",
        "    \n",
        "    if experiment:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"FETCHING RESULTS FROM EXPERIMENT\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        runs = client.search_runs(experiment_ids=experiment_id)\n",
        "        run_data = []\n",
        "        \n",
        "        for run in runs:\n",
        "            metrics = run.data.metrics\n",
        "            params = run.data.params\n",
        "            \n",
        "            run_data.append({\n",
        "                'run_id': run.info.run_id,\n",
        "                'algo_name': params.get('algo_name', 'N/A'),\n",
        "                'imbalance_handling': params.get('imbalance_handling', 'N/A'),\n",
        "                'accuracy': metrics.get('accuracy', 0.0),\n",
        "                'weighted_f1': metrics.get(OPTIMAL_METRIC, 0.0),\n",
        "                '0_f1': metrics.get('0_f1-score', 0.0),\n",
        "                '1_f1': metrics.get('1_f1-score', 0.0),\n",
        "                '2_f1': metrics.get('2_f1-score', 0.0),\n",
        "                'run_name': run.data.tags.get('mlflow.runName')\n",
        "            })\n",
        "\n",
        "        df_results = pd.DataFrame(run_data)\n",
        "        \n",
        "        # Create composite score: average of accuracy and weighted F1\n",
        "        df_results['composite_score'] = (df_results['accuracy'] + df_results['weighted_f1']) / 2\n",
        "        \n",
        "        # Sort by composite score\n",
        "        df_results = df_results.sort_values(by='composite_score', ascending=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"TOP 10 MODELS (Sorted by Composite Score: Avg of Accuracy & Weighted F1)\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results[['algo_name', 'imbalance_handling', 'accuracy', \n",
        "                         'weighted_f1', 'composite_score', '2_f1']].head(10).to_string(index=False))\n",
        "        \n",
        "        # Rankings by different metrics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RANKINGS BY DIFFERENT METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(\"\\nüìä Top 5 by Accuracy:\")\n",
        "        top_acc = df_results.nlargest(5, 'accuracy')\n",
        "        for idx, row in top_acc.iterrows():\n",
        "            print(f\"  {row['algo_name']:25s} ({row['imbalance_handling']:15s}) - Accuracy: {row['accuracy']:.4f}\")\n",
        "        \n",
        "        print(\"\\nüìä Top 5 by Weighted F1-Score:\")\n",
        "        top_f1 = df_results.nlargest(5, 'weighted_f1')\n",
        "        for idx, row in top_f1.iterrows():\n",
        "            print(f\"  {row['algo_name']:25s} ({row['imbalance_handling']:15s}) - Weighted F1: {row['weighted_f1']:.4f}\")\n",
        "        \n",
        "        print(\"\\nüìä Top 5 by Minority Class (2) F1-Score:\")\n",
        "        top_minority = df_results.nlargest(5, '2_f1')\n",
        "        for idx, row in top_minority.iterrows():\n",
        "            print(f\"  {row['algo_name']:25s} ({row['imbalance_handling']:15s}) - Class 2 F1: {row['2_f1']:.4f}\")\n",
        "        \n",
        "        # Algorithm + Sampling Method Analysis\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"BEST SAMPLING METHOD FOR EACH ALGORITHM\")\n",
        "        print(\"=\"*80)\n",
        "        for algo in df_results['algo_name'].unique():\n",
        "            if algo != 'N/A':\n",
        "                algo_df = df_results[df_results['algo_name'] == algo]\n",
        "                best_row = algo_df.iloc[0]\n",
        "                print(f\"\\n{algo}:\")\n",
        "                print(f\"  Best Sampling: {best_row['imbalance_handling']}\")\n",
        "                print(f\"  Accuracy: {best_row['accuracy']:.4f}\")\n",
        "                print(f\"  Weighted F1: {best_row['weighted_f1']:.4f}\")\n",
        "                print(f\"  Minority F1: {best_row['2_f1']:.4f}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üèÜ BEST OVERALL MODEL (by Composite Score)\")\n",
        "        print(\"=\"*80)\n",
        "        best = df_results.iloc[0]\n",
        "        print(f\"Algorithm: {best['algo_name']}\")\n",
        "        print(f\"Imbalance Handling: {best['imbalance_handling']}\")\n",
        "        print(f\"Composite Score: {best['composite_score']:.4f}\")\n",
        "        print(f\"Accuracy: {best['accuracy']:.4f}\")\n",
        "        print(f\"Weighted F1-Score: {best['weighted_f1']:.4f}\")\n",
        "        print(f\"Class 0 F1: {best['0_f1']:.4f}\")\n",
        "        print(f\"Class 1 F1: {best['1_f1']:.4f}\")\n",
        "        print(f\"Class 2 (Minority) F1: {best['2_f1']:.4f}\")\n",
        "        print(f\"Run ID: {best['run_id']}\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(\"\\nüí° Key Insights:\")\n",
        "        print(\"   ‚úì Each algorithm trained on undersampling, oversampling, and ADASYN\")\n",
        "        print(\"   ‚úì Best model selected from all 12 combinations (4 algos √ó 3 methods)\")\n",
        "        print(\"   ‚úì Composite Score balances accuracy with class-wise F1 performance\")\n",
        "        print(\"   ‚úì This approach avoids ensemble voting that may reduce performance\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
