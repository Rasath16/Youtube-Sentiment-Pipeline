{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install -q optuna lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This experiment compares the performance of several classification algorithms (Logistic Regression, Naive Bayes, SVM, XGBoost, LightGBM). We apply Hyperparameter Tuning (HPT) to the complex models using Optuna, while fixing the feature engineering pipeline based on previous optimal choices:\n",
        "\n",
        "* **Vectorization:** TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "* **N-gram Range:** Bigram `(1, 2)` (Unigrams and Bigrams)\n",
        "* **Max Features:** 1000\n",
        "* **Imbalance Handling:** Undersampling (`RandomUnderSampler`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC # Using LinearSVC for sparse data compatibility\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MLflow and Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 MLflow Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mlflow_config"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://mlfow-bucket-2025/927563970798110109', creation_time=1762945494781, experiment_id='927563970798110109', last_update_time=1762945494781, lifecycle_stage='active', name='Experiment 5 - Model Comparision (TFIDF Bigram 1000 + Undersampling)', tags={}>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the remote tracking server URI\n",
        "mlflow.set_tracking_uri(\"http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/\")\n",
        "\n",
        "# Set or create a new experiment\n",
        "mlflow.set_experiment(\"Experiment 5 - Model Comparision (TFIDF Bigram 1000 + Undersampling)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Data Loading, Remapping, and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (36662, 2)\n"
          ]
        }
      ],
      "source": [
        "# Load preprocessed data and clean missing values\n",
        "df = pd.read_csv('../data/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
        "\n",
        "# Remap class labels [-1, 0, 1] to [0, 1, 2] for model compatibility\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "df = df.dropna(subset=['category']) # Final check for NaNs\n",
        "\n",
        "print(f\"Data shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vectorize_and_undersample"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Training Data Shape: (29329, 1000)\n",
            "Resampled Training Data Shape after Undersampling: (19794, 1000)\n",
            "Test Data Shape: (7333, 1000)\n"
          ]
        }
      ],
      "source": [
        "# Define fixed feature parameters\n",
        "ngram_range = (1, 2)  # Bigram setting\n",
        "max_features = 1000   # Fixed Max Features\n",
        "imbalance_method = \"undersampling\"\n",
        "\n",
        "# Split data BEFORE vectorization and resampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], \n",
        "                                                              test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "# 1. Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)  \n",
        "X_test_vec = vectorizer.transform(X_test)  \n",
        "\n",
        "# 2. Undersampling using RandomUnderSampler\n",
        "sampler = RandomUnderSampler(random_state=42)\n",
        "X_train_res, y_train_res = sampler.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "print(f\"Original Training Data Shape: {X_train_vec.shape}\")\n",
        "print(f\"Resampled Training Data Shape after Undersampling: {X_train_res.shape}\")\n",
        "print(f\"Test Data Shape: {X_test_vec.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLflow Logging and Evaluation Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "log_mlflow_helper"
      },
      "outputs": [],
      "source": [
        "def log_mlflow(model_name, model, params=None):\n",
        "    \"\"\"Trains and logs a single model run to MLflow with evaluation metrics.\"\"\"\n",
        "    with mlflow.start_run():\n",
        "        # Set tags and log fixed parameters\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_Undersample_TFIDF(1000)_HPT\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"multi_algo_hpt\")\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", str(ngram_range))\n",
        "        mlflow.log_param(\"max_features\", max_features)\n",
        "        mlflow.log_param(\"imbalance_handling\", imbalance_method)\n",
        "        \n",
        "        # Log specific model hyperparameters\n",
        "        if params:\n",
        "            for key, value in params.items():\n",
        "                mlflow.log_param(key, value)\n",
        "\n",
        "        # Train model on resampled data\n",
        "        model.fit(X_train_res, y_train_res)\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        # Log metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix (optional but good practice)\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.title(f\"Confusion Matrix: {model_name}\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.savefig(f\"conf_matrix_{model_name}.png\")\n",
        "        mlflow.log_artifact(f\"conf_matrix_{model_name}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "        \n",
        "        print(f\"Logged {model_name} with Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Hyperparameter Tuning Objectives (Optuna)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "optuna_objectives"
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 10 # Keep trials low for complexity management\n",
        "\n",
        "# --- 4.1 Logistic Regression Objective ---\n",
        "def objective_lr(trial):\n",
        "    C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])\n",
        "    \n",
        "    model = LogisticRegression(C=C, solver=solver, random_state=42, multi_class='auto', max_iter=1000)\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "\n",
        "# --- 4.2 Linear SVM Objective ---\n",
        "def objective_svc(trial):\n",
        "    C = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
        "    \n",
        "    # Use LinearSVC which is better suited for large, sparse datasets\n",
        "    model = LinearSVC(C=C, random_state=42, max_iter=1000, dual='auto')\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "\n",
        "# --- 4.3 XGBoost Objective ---\n",
        "def objective_xgboost(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 7)\n",
        "\n",
        "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, \n",
        "                          random_state=42, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "\n",
        "# --- 4.4 LightGBM Objective ---\n",
        "def objective_lightgbm(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
        "    num_leaves = trial.suggest_int('num_leaves', 10, 50)\n",
        "\n",
        "    model = LGBMClassifier(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves, \n",
        "                           random_state=42, verbose=-1)\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    return accuracy_score(y_test, model.predict(X_test_vec))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Execution and MLflow Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "execution_pipeline"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting baseline run for MultinomialNB ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 16:44:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 16:44:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged MultinomialNB with Accuracy: 0.7000\n",
            "üèÉ View run MultinomialNB_Undersample_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109/runs/6138376b73db4c21af6c0f255f96bcd4\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:44:48,288] A new study created in memory with name: LogisticRegression\n",
            "[I 2025-11-12 16:44:48,347] Trial 0 finished with value: 0.6631665075685258 and parameters: {'C': 0.003554156887954465, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.6631665075685258.\n",
            "[I 2025-11-12 16:44:48,450] Trial 1 finished with value: 0.7638074457929905 and parameters: {'C': 0.2706288896466599, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7638074457929905.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting HPT for LogisticRegression (10 trials) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:44:48,500] Trial 2 finished with value: 0.6650756852584209 and parameters: {'C': 0.0025982079054921326, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7638074457929905.\n",
            "[I 2025-11-12 16:44:48,641] Trial 3 finished with value: 0.7318969044047456 and parameters: {'C': 0.06854300063095319, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7638074457929905.\n",
            "[I 2025-11-12 16:44:48,744] Trial 4 finished with value: 0.7494886131187781 and parameters: {'C': 0.1445057242570108, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7638074457929905.\n",
            "[I 2025-11-12 16:44:48,841] Trial 5 finished with value: 0.778671757807173 and parameters: {'C': 1.278413171841183, 'solver': 'liblinear'}. Best is trial 5 with value: 0.778671757807173.\n",
            "[I 2025-11-12 16:44:48,916] Trial 6 finished with value: 0.7583526523932906 and parameters: {'C': 0.24415992458386357, 'solver': 'liblinear'}. Best is trial 5 with value: 0.778671757807173.\n",
            "[I 2025-11-12 16:44:48,962] Trial 7 finished with value: 0.6679394517932633 and parameters: {'C': 0.004159332130160294, 'solver': 'liblinear'}. Best is trial 5 with value: 0.778671757807173.\n",
            "[I 2025-11-12 16:44:49,189] Trial 8 finished with value: 0.7781262784672031 and parameters: {'C': 1.4590644023598764, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.778671757807173.\n",
            "[I 2025-11-12 16:44:49,227] Trial 9 finished with value: 0.6656211645983908 and parameters: {'C': 0.0027721481661907373, 'solver': 'liblinear'}. Best is trial 5 with value: 0.778671757807173.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LogisticRegression Params: {'C': 1.278413171841183, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 16:45:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 16:45:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged LogisticRegression_HPT with Accuracy: 0.7787\n",
            "üèÉ View run LogisticRegression_HPT_Undersample_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109/runs/69897c926c81491c8d0e5555a9d22881\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:45:41,308] A new study created in memory with name: LinearSVC\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting HPT for LinearSVC (10 trials) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:45:41,562] Trial 0 finished with value: 0.783035592526933 and parameters: {'C': 6.724496257841721}. Best is trial 0 with value: 0.783035592526933.\n",
            "[I 2025-11-12 16:45:41,683] Trial 1 finished with value: 0.7849447702168281 and parameters: {'C': 0.5263589688942403}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:41,830] Trial 2 finished with value: 0.7834447020319105 and parameters: {'C': 1.5873598423695072}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,008] Trial 3 finished with value: 0.7837174417018955 and parameters: {'C': 1.9376355032265133}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,148] Trial 4 finished with value: 0.7834447020319105 and parameters: {'C': 2.1900012916767624}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,259] Trial 5 finished with value: 0.780035456157098 and parameters: {'C': 0.13232583607003803}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,414] Trial 6 finished with value: 0.7834447020319105 and parameters: {'C': 2.1747646881832137}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,635] Trial 7 finished with value: 0.782762852856948 and parameters: {'C': 9.848935246667331}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,770] Trial 8 finished with value: 0.7849447702168281 and parameters: {'C': 0.36373574309133233}. Best is trial 1 with value: 0.7849447702168281.\n",
            "[I 2025-11-12 16:45:42,931] Trial 9 finished with value: 0.783853811536888 and parameters: {'C': 3.1240233400783706}. Best is trial 1 with value: 0.7849447702168281.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LinearSVC Params: {'C': 0.5263589688942403}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 16:46:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 16:46:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged LinearSVC_HPT with Accuracy: 0.7849\n",
            "üèÉ View run LinearSVC_HPT_Undersample_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109/runs/4a3eacc03c114d33bf413326b80f5b53\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:46:32,617] A new study created in memory with name: XGBoost\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting HPT for XGBoost (10 trials) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:47:14,560] Trial 0 finished with value: 0.588163098322651 and parameters: {'n_estimators': 199, 'learning_rate': 0.0028322158800103484, 'max_depth': 6}. Best is trial 0 with value: 0.588163098322651.\n",
            "[I 2025-11-12 16:47:45,946] Trial 1 finished with value: 0.7061230055911633 and parameters: {'n_estimators': 160, 'learning_rate': 0.04039843724008596, 'max_depth': 6}. Best is trial 1 with value: 0.7061230055911633.\n",
            "[I 2025-11-12 16:48:02,803] Trial 2 finished with value: 0.569889540433656 and parameters: {'n_estimators': 71, 'learning_rate': 0.001662230581776005, 'max_depth': 6}. Best is trial 1 with value: 0.7061230055911633.\n",
            "[I 2025-11-12 16:48:25,636] Trial 3 finished with value: 0.6454384290195009 and parameters: {'n_estimators': 149, 'learning_rate': 0.01598776649910289, 'max_depth': 5}. Best is trial 1 with value: 0.7061230055911633.\n",
            "[I 2025-11-12 16:48:51,762] Trial 4 finished with value: 0.5779353606982136 and parameters: {'n_estimators': 89, 'learning_rate': 0.00407293957384463, 'max_depth': 7}. Best is trial 1 with value: 0.7061230055911633.\n",
            "[I 2025-11-12 16:49:13,219] Trial 5 finished with value: 0.7280785490249557 and parameters: {'n_estimators': 118, 'learning_rate': 0.08748905697283263, 'max_depth': 6}. Best is trial 5 with value: 0.7280785490249557.\n",
            "[I 2025-11-12 16:49:29,771] Trial 6 finished with value: 0.7258966316650757 and parameters: {'n_estimators': 125, 'learning_rate': 0.09313517089473976, 'max_depth': 5}. Best is trial 5 with value: 0.7280785490249557.\n",
            "[I 2025-11-12 16:50:01,130] Trial 7 finished with value: 0.5877539888176735 and parameters: {'n_estimators': 131, 'learning_rate': 0.004281627429014863, 'max_depth': 6}. Best is trial 5 with value: 0.7280785490249557.\n",
            "[I 2025-11-12 16:50:29,794] Trial 8 finished with value: 0.566889404063821 and parameters: {'n_estimators': 176, 'learning_rate': 0.0021180589928388688, 'max_depth': 5}. Best is trial 5 with value: 0.7280785490249557.\n",
            "[I 2025-11-12 16:50:36,998] Trial 9 finished with value: 0.5760261830083185 and parameters: {'n_estimators': 71, 'learning_rate': 0.011613245409274466, 'max_depth': 4}. Best is trial 5 with value: 0.7280785490249557.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best XGBoost Params: {'n_estimators': 118, 'learning_rate': 0.08748905697283263, 'max_depth': 6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 16:51:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 16:51:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged XGBoost_HPT with Accuracy: 0.7281\n",
            "üèÉ View run XGBoost_HPT_Undersample_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109/runs/ba5abf9dc9884bb0a686a0157c0028f2\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:51:52,556] A new study created in memory with name: LightGBM\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting HPT for LightGBM (10 trials) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 16:52:00,311] Trial 0 finished with value: 0.7823537433519705 and parameters: {'n_estimators': 157, 'learning_rate': 0.04099673118007485, 'num_leaves': 45}. Best is trial 0 with value: 0.7823537433519705.\n",
            "[I 2025-11-12 16:52:02,712] Trial 1 finished with value: 0.7741715532524206 and parameters: {'n_estimators': 80, 'learning_rate': 0.07745214019639735, 'num_leaves': 24}. Best is trial 0 with value: 0.7823537433519705.\n",
            "[I 2025-11-12 16:52:09,518] Trial 2 finished with value: 0.7273966998499932 and parameters: {'n_estimators': 163, 'learning_rate': 0.004405280808174647, 'num_leaves': 36}. Best is trial 0 with value: 0.7823537433519705.\n",
            "[I 2025-11-12 16:52:18,085] Trial 3 finished with value: 0.7828992226919406 and parameters: {'n_estimators': 180, 'learning_rate': 0.032509495822559915, 'num_leaves': 43}. Best is trial 3 with value: 0.7828992226919406.\n",
            "[I 2025-11-12 16:52:21,370] Trial 4 finished with value: 0.7548070366834856 and parameters: {'n_estimators': 165, 'learning_rate': 0.032226778384045675, 'num_leaves': 16}. Best is trial 3 with value: 0.7828992226919406.\n",
            "[I 2025-11-12 16:52:24,620] Trial 5 finished with value: 0.6735306150279559 and parameters: {'n_estimators': 171, 'learning_rate': 0.0063759064360990525, 'num_leaves': 14}. Best is trial 3 with value: 0.7828992226919406.\n",
            "[I 2025-11-12 16:52:27,571] Trial 6 finished with value: 0.6958952679667257 and parameters: {'n_estimators': 84, 'learning_rate': 0.006046482586474513, 'num_leaves': 26}. Best is trial 3 with value: 0.7828992226919406.\n",
            "[I 2025-11-12 16:52:33,085] Trial 7 finished with value: 0.6911223237419882 and parameters: {'n_estimators': 145, 'learning_rate': 0.001026389558983948, 'num_leaves': 27}. Best is trial 3 with value: 0.7828992226919406.\n",
            "[I 2025-11-12 16:52:36,581] Trial 8 finished with value: 0.7073503341060957 and parameters: {'n_estimators': 73, 'learning_rate': 0.002165321506941824, 'num_leaves': 33}. Best is trial 3 with value: 0.7828992226919406.\n",
            "[I 2025-11-12 16:52:44,801] Trial 9 finished with value: 0.7818082640120005 and parameters: {'n_estimators': 150, 'learning_rate': 0.07746728232846488, 'num_leaves': 46}. Best is trial 3 with value: 0.7828992226919406.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LightGBM Params: {'n_estimators': 180, 'learning_rate': 0.032509495822559915, 'num_leaves': 43}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/12 16:53:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/12 16:53:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged LightGBM_HPT with Accuracy: 0.7829\n",
            "üèÉ View run LightGBM_HPT_Undersample_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109/runs/2136aeac43a24180b4f7131843c3d81b\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/927563970798110109\n"
          ]
        }
      ],
      "source": [
        "def run_tuning_and_log(model_name, objective_func, n_trials):\n",
        "    \"\"\"Runs Optuna HPT for a given model and logs the best model to MLflow.\"\"\"\n",
        "    print(f\"\\n--- Starting HPT for {model_name} ({n_trials} trials) ---\")\n",
        "    study = optuna.create_study(direction=\"maximize\", study_name=model_name)\n",
        "    study.optimize(objective_func, n_trials=n_trials)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    print(f\"Best {model_name} Params: {best_params}\")\n",
        "\n",
        "    # Re-initialize the best model based on its type\n",
        "    if model_name == 'LogisticRegression':\n",
        "        best_model = LogisticRegression(random_state=42, multi_class='auto', max_iter=1000, **best_params)\n",
        "    elif model_name == 'LinearSVC':\n",
        "        best_model = LinearSVC(random_state=42, max_iter=1000, dual='auto', **best_params)\n",
        "    elif model_name == 'XGBoost':\n",
        "        best_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1, **best_params)\n",
        "    elif model_name == 'LightGBM':\n",
        "        best_model = LGBMClassifier(random_state=42, verbose=-1, **best_params)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model type: {model_name}\")\n",
        "\n",
        "    log_mlflow(f\"{model_name}_HPT\", best_model, params=best_params)\n",
        "\n",
        "\n",
        "def run_simple_model_and_log(model_name, model_class, params=None):\n",
        "    \"\"\"Initializes a simple model (no HPT) and logs it to MLflow.\"\"\"\n",
        "    print(f\"\\n--- Starting baseline run for {model_name} ---\")\n",
        "    if params:\n",
        "        model = model_class(random_state=42, **params)\n",
        "    else:\n",
        "        model = model_class()\n",
        "    \n",
        "    # For MNB, alpha should be tuned, but we run a default simple value for comparison\n",
        "    if model_name == 'MultinomialNB':\n",
        "        model = MultinomialNB(alpha=1.0) \n",
        "        params = {'alpha': 1.0}\n",
        "    \n",
        "    log_mlflow(model_name, model, params=params)\n",
        "\n",
        "\n",
        "# --- Execution Pipeline ---\n",
        "\n",
        "# 1. Simple Models (Multinomial Naive Bayes)\n",
        "run_simple_model_and_log('MultinomialNB', MultinomialNB)\n",
        "\n",
        "# 2. Tuned Models\n",
        "models_to_tune = [\n",
        "    ('LogisticRegression', objective_lr),\n",
        "    ('LinearSVC', objective_svc),\n",
        "    ('XGBoost', objective_xgboost),\n",
        "    ('LightGBM', objective_lightgbm)\n",
        "]\n",
        "\n",
        "for model_name, objective in models_to_tune:\n",
        "    run_tuning_and_log(model_name, objective, N_TRIALS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusion and Next Steps\n",
        "The complete set of model performances, including optimized hyperparameters, is now logged in the MLflow UI. The next step is typically stacking or selecting the single best performing model based on comprehensive evaluation metrics, especially F1-scores for the minority classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching runs for Experiment ID: 927563970798110109\n",
            "\n",
            "==================================================\n",
            "RESULTS SORTED BY: weighted avg_f1-score\n",
            "==================================================\n",
            "                                            run_name               algo_name  \\\n",
            "2          LinearSVC_HPT_Undersample_TFIDF(1000)_HPT           LinearSVC_HPT   \n",
            "0           LightGBM_HPT_Undersample_TFIDF(1000)_HPT            LightGBM_HPT   \n",
            "3  LogisticRegression_HPT_Undersample_TFIDF(1000)...  LogisticRegression_HPT   \n",
            "1            XGBoost_HPT_Undersample_TFIDF(1000)_HPT             XGBoost_HPT   \n",
            "4          MultinomialNB_Undersample_TFIDF(1000)_HPT           MultinomialNB   \n",
            "\n",
            "   accuracy  weighted avg_f1-score  0_f1-score  1_f1-score  2_f1-score  \n",
            "2  0.784945               0.782771    0.835863    0.800831    0.666874  \n",
            "0  0.782899               0.780663    0.835173    0.800698    0.658816  \n",
            "3  0.778672               0.776854    0.831210    0.796804    0.655405  \n",
            "1  0.728079               0.724808    0.781575    0.741100    0.606658  \n",
            "4  0.699986               0.703944    0.735410    0.737449    0.591671  \n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "BEST MODEL FOUND:\n",
            "==================================================\n",
            "Algorithm: LinearSVC_HPT\n",
            "Run Name: LinearSVC_HPT_Undersample_TFIDF(1000)_HPT\n",
            "Run ID: 4a3eacc03c114d33bf413326b80f5b53\n",
            "Overall Accuracy: 0.7849\n",
            "weighted avg_f1-score: 0.7828\n",
            "\n",
            "Best Model Hyperparameters:\n",
            "  C: 0.5263589688942403\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "OPTIMAL_METRIC = \"weighted avg_f1-score\"\n",
        "MLFLOW_TRACKING_URI = \"http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/\"\n",
        "EXPERIMENT_NAME = \"Experiment 5 - Model Comparision (TFIDF Bigram 1000 + Undersampling)\"\n",
        "\n",
        "\n",
        "try:\n",
        "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "    client = mlflow.tracking.MlflowClient()\n",
        "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
        "    \n",
        "    if experiment is None:\n",
        "        print(f\"Error: Experiment '{EXPERIMENT_NAME}' not found on the server.\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"Fetching runs for Experiment ID: {experiment_id}\")\n",
        "\n",
        "        # Fetch all runs in the experiment\n",
        "        runs = client.search_runs(experiment_ids=experiment_id)\n",
        "\n",
        "        run_data = []\n",
        "        for run in runs:\n",
        "            # Extract relevant metrics and parameters\n",
        "            metrics = {k: v for k, v in run.data.metrics.items() if k.endswith('f1-score') or k == 'accuracy'}\n",
        "            params = run.data.params\n",
        "            \n",
        "            run_data.append({\n",
        "                'run_id': run.info.run_id,\n",
        "                'status': run.info.status,\n",
        "                'algo_name': params.get('algo_name', 'N/A'),\n",
        "                'accuracy': run.data.metrics.get('accuracy', 0.0),\n",
        "                **metrics,\n",
        "                'max_features': params.get('max_features', 'N/A'),\n",
        "                'imbalance_handling': params.get('imbalance_handling', 'N/A'),\n",
        "                'run_name': run.data.tags.get('mlflow.runName')\n",
        "            })\n",
        "\n",
        "        if not run_data:\n",
        "            print(\"No completed runs found in the experiment.\")\n",
        "        else:\n",
        "            df_results = pd.DataFrame(run_data)\n",
        "            \n",
        "            # --- EVALUATE AND FIND BEST MODEL ---\n",
        "            \n",
        "            # Ensure the optimal metric column is numeric before sorting\n",
        "            if OPTIMAL_METRIC in df_results.columns:\n",
        "                df_results[OPTIMAL_METRIC] = pd.to_numeric(df_results[OPTIMAL_METRIC], errors='coerce')\n",
        "                \n",
        "                # Sort by the optimal metric (descending)\n",
        "                df_best = df_results.sort_values(by=OPTIMAL_METRIC, ascending=False)\n",
        "                best_model_run = df_best.iloc[0]\n",
        "\n",
        "                print(\"\\n\" + \"=\"*50)\n",
        "                print(f\"RESULTS SORTED BY: {OPTIMAL_METRIC}\")\n",
        "                print(\"=\"*50)\n",
        "                # Display the top 5 models\n",
        "                print(df_best[['run_name', 'algo_name', 'accuracy', OPTIMAL_METRIC, '0_f1-score', '1_f1-score', '2_f1-score']].head())\n",
        "                print(\"=\"*50)\n",
        "\n",
        "                # --- BEST MODEL SUMMARY ---\n",
        "                print(\"\\n\" + \"=\"*50)\n",
        "                print(\"BEST MODEL FOUND:\")\n",
        "                print(\"=\"*50)\n",
        "                print(f\"Algorithm: {best_model_run['algo_name']}\")\n",
        "                print(f\"Run Name: {best_model_run['run_name']}\")\n",
        "                print(f\"Run ID: {best_model_run['run_id']}\")\n",
        "                print(f\"Overall Accuracy: {best_model_run['accuracy']:.4f}\")\n",
        "                print(f\"{OPTIMAL_METRIC}: {best_model_run[OPTIMAL_METRIC]:.4f}\")\n",
        "                \n",
        "                # Retrieve all parameters for the best run\n",
        "                best_run_params = client.get_run(best_model_run['run_id']).data.params\n",
        "                print(\"\\nBest Model Hyperparameters:\")\n",
        "                # Filter for core hyperparameters (excluding fixed feature/imbalance params)\n",
        "                hp_keys = ['C', 'learning_rate', 'n_estimators', 'max_depth', 'num_leaves', 'solver', 'alpha']\n",
        "                best_hps = {k: v for k, v in best_run_params.items() if k in hp_keys}\n",
        "                \n",
        "                for k, v in best_hps.items():\n",
        "                    print(f\"  {k}: {v}\")\n",
        "                print(\"=\"*50)\n",
        "\n",
        "            else:\n",
        "                print(f\"Optimal Metric '{OPTIMAL_METRIC}' not found in run metrics. Please check your logging setup.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while connecting to MLflow or processing data: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
