{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install -q optuna lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This experiment compares the performance of several classification algorithms (Logistic Regression, Naive Bayes, SVM, XGBoost, LightGBM). We apply Hyperparameter Tuning (HPT) to the complex models using Optuna, while fixing the feature engineering pipeline based on previous optimal choices:\n",
        "\n",
        "* **Vectorization:** TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "* **N-gram Range:** Bigram `(1, 2)` (Unigrams and Bigrams)\n",
        "* **Max Features:** 1000\n",
        "* **Imbalance Handling:** Undersampling (`RandomUnderSampler`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MLflow and Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 MLflow Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mlflow_config"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://mlfow-bucket-2025/17', creation_time=1763217601948, experiment_id='17', last_update_time=1763217601948, lifecycle_stage='active', name='Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5', tags={'mlflow.experimentKind': 'custom_model_development'}>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the remote tracking server URI\n",
        "mlflow.set_tracking_uri(\"http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/\")\n",
        "\n",
        "# Set or create a new experiment\n",
        "mlflow.set_experiment(\"Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Data Loading, Remapping, and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (36662, 2)\n",
            "Class distribution:\n",
            "category\n",
            "0    12644\n",
            "1    15770\n",
            "2     8248\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Original Training Data Shape: (29329, 1000)\n",
            "Test Data Shape: (7333, 1000)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../data/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"Class distribution:\\n{df['category'].value_counts().sort_index()}\")\n",
        "\n",
        "# Fixed parameters\n",
        "ngram_range = (1, 2)\n",
        "max_features = 1000\n",
        "\n",
        "# Split and vectorize\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_comment'], df['category'], \n",
        "    test_size=0.2, random_state=42, stratify=df['category']\n",
        ")\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\nOriginal Training Data Shape: {X_train_vec.shape}\")\n",
        "print(f\"Test Data Shape: {X_test_vec.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resampled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CREATING 3 RESAMPLED DATASETS (TOP 3 IMBALANCE METHODS)\n",
            "================================================================================\n",
            "1. Undersampled: (19794, 1000)\n",
            "2. Oversampled: (37848, 1000)\n",
            "3. ADASYN: (35909, 1000)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING 3 RESAMPLED DATASETS (TOP 3 IMBALANCE METHODS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Method 1: Undersampling\n",
        "sampler_under = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = sampler_under.fit_resample(X_train_vec, y_train)\n",
        "print(f\"1. Undersampled: {X_train_under.shape}\")\n",
        "\n",
        "# Method 2: Oversampling\n",
        "sampler_over = RandomOverSampler(random_state=42)\n",
        "X_train_over, y_train_over = sampler_over.fit_resample(X_train_vec, y_train)\n",
        "print(f\"2. Oversampled: {X_train_over.shape}\")\n",
        "\n",
        "# Method 3: ADASYN\n",
        "sampler_adasyn = ADASYN(random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = sampler_adasyn.fit_resample(X_train_vec, y_train)\n",
        "print(f\"3. ADASYN: {X_train_adasyn.shape}\")\n",
        "\n",
        "# Store all datasets\n",
        "datasets = {\n",
        "    'undersampling': (X_train_under, y_train_under),\n",
        "    'oversampling': (X_train_over, y_train_over),\n",
        "    'adasyn': (X_train_adasyn, y_train_adasyn)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLflow Logging and Evaluation Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "log_mlflow_helper"
      },
      "outputs": [],
      "source": [
        "def log_mlflow(model_name, model, params=None, imbalance_method=\"undersampling\"):\n",
        "    with mlflow.start_run():\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_{imbalance_method}_TFIDF(1000)_HPT\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"multi_algo_hpt\")\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", str(ngram_range))\n",
        "        mlflow.log_param(\"max_features\", max_features)\n",
        "        mlflow.log_param(\"imbalance_handling\", imbalance_method)\n",
        "        \n",
        "        if params:\n",
        "            for key, value in params.items():\n",
        "                mlflow.log_param(key, value)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        # Log metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.title(f\"Confusion Matrix: {model_name} ({imbalance_method})\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.savefig(f\"conf_matrix_{model_name}_{imbalance_method}.png\")\n",
        "        mlflow.log_artifact(f\"conf_matrix_{model_name}_{imbalance_method}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "        \n",
        "        print(f\"    ‚úì Logged with Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Hyperparameter Tuning Objectives (Optuna)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "optuna_objectives"
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 10\n",
        "\n",
        "def tune_logistic_regression(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
        "        solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])\n",
        "        model = LogisticRegression(C=C, solver=solver, random_state=42, multi_class='auto', max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params\n",
        "\n",
        "def tune_linear_svc(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        C = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
        "        model = LinearSVC(C=C, random_state=42, max_iter=1000, dual='auto')\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params\n",
        "\n",
        "def tune_xgboost(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
        "        max_depth = trial.suggest_int('max_depth', 3, 7)\n",
        "        model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth,\n",
        "                             random_state=42, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params\n",
        "\n",
        "def tune_lightgbm(X_train, y_train):\n",
        "    def objective(trial):\n",
        "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
        "        num_leaves = trial.suggest_int('num_leaves', 10, 50)\n",
        "        model = LGBMClassifier(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves,\n",
        "                              random_state=42, verbose=-1)\n",
        "        model.fit(X_train, y_train)\n",
        "        return accuracy_score(y_test, model.predict(X_test_vec))\n",
        "    \n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
        "    return study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Execution and MLflow Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "execution_pipeline"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING MODEL TRAINING WITH ALL SAMPLING METHODS\n",
            "================================================================================\n",
            "Strategy: Train each algorithm on all 3 sampling methods separately\n",
            "This creates 12 models (4 algorithms √ó 3 sampling methods)\n",
            "MLflow will track all and identify the best combination\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "BASELINE: MultinomialNB (No HPT)\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:08:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:09:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7000\n",
            "üèÉ View run MultinomialNB_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/03490333fe014eefbedad5d9db0a1bd9\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:09:07,678] A new study created in memory with name: no-name-05dce9b7-d596-414a-9c60-47b1757eb243\n",
            "[I 2025-11-15 21:09:07,829] Trial 0 finished with value: 0.7809900450020455 and parameters: {'C': 2.8430254938819615, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7809900450020455.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING LogisticRegression ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:09:07,970] Trial 1 finished with value: 0.6941224601118232 and parameters: {'C': 0.017073324868662743, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,061] Trial 2 finished with value: 0.7584890222282831 and parameters: {'C': 0.239696894463243, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,165] Trial 3 finished with value: 0.7749897722623755 and parameters: {'C': 0.9082168404175678, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,210] Trial 4 finished with value: 0.6808945861175508 and parameters: {'C': 0.011122852543296783, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,276] Trial 5 finished with value: 0.7231692349652257 and parameters: {'C': 0.06947622960784537, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,318] Trial 6 finished with value: 0.6669848629483158 and parameters: {'C': 0.0032356524270157655, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,375] Trial 7 finished with value: 0.6838947224873858 and parameters: {'C': 0.016810666574137535, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,406] Trial 8 finished with value: 0.6624846583935633 and parameters: {'C': 0.0030352935642267583, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7809900450020455.\n",
            "[I 2025-11-15 21:09:08,489] Trial 9 finished with value: 0.7314877948997681 and parameters: {'C': 0.0686329331290501, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7809900450020455.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 2.8430254938819615, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:09:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:09:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7810\n",
            "üèÉ View run LogisticRegression_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/62d56a3afa6c4a86ae59634091f762bc\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:09:56,142] A new study created in memory with name: no-name-4cbd1547-ff1a-4472-ba12-c4719349083c\n",
            "[I 2025-11-15 21:09:56,210] Trial 0 finished with value: 0.6653484249284058 and parameters: {'C': 0.0012769387851858896, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.6653484249284058.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:09:56,427] Trial 1 finished with value: 0.7790808673121505 and parameters: {'C': 0.4451393088430444, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7790808673121505.\n",
            "[I 2025-11-15 21:09:56,989] Trial 2 finished with value: 0.774307923087413 and parameters: {'C': 7.322040062779014, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7790808673121505.\n",
            "[I 2025-11-15 21:09:57,037] Trial 3 finished with value: 0.6639847265784808 and parameters: {'C': 0.0011942528802026126, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7790808673121505.\n",
            "[I 2025-11-15 21:09:57,230] Trial 4 finished with value: 0.7162143733806082 and parameters: {'C': 0.025034434885284267, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7790808673121505.\n",
            "[I 2025-11-15 21:09:57,488] Trial 5 finished with value: 0.7778535387972181 and parameters: {'C': 0.284561013137554, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7790808673121505.\n",
            "[I 2025-11-15 21:09:57,743] Trial 6 finished with value: 0.7798990863221056 and parameters: {'C': 0.6079595364809569, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7798990863221056.\n",
            "[I 2025-11-15 21:09:57,838] Trial 7 finished with value: 0.6811673257875358 and parameters: {'C': 0.006330933555951901, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7798990863221056.\n",
            "[I 2025-11-15 21:09:58,097] Trial 8 finished with value: 0.771307786717578 and parameters: {'C': 0.19347398779078148, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7798990863221056.\n",
            "[I 2025-11-15 21:09:58,193] Trial 9 finished with value: 0.7208509477703532 and parameters: {'C': 0.019986783555005667, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7798990863221056.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 0.6079595364809569, 'solver': 'lbfgs'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:10:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:10:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7799\n",
            "üèÉ View run LogisticRegression_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/0d8230c421384624bea20f1ccdb659ae\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:10:46,130] A new study created in memory with name: no-name-c8e3e74b-8e29-4fe5-88ca-9d2279a10221\n",
            "[I 2025-11-15 21:10:46,202] Trial 0 finished with value: 0.5525705713896086 and parameters: {'C': 0.003211718299112583, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5525705713896086.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:10:46,494] Trial 1 finished with value: 0.7748534024273831 and parameters: {'C': 4.481530835385039, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:46,725] Trial 2 finished with value: 0.7696713486976681 and parameters: {'C': 1.1589707588570284, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:47,128] Trial 3 finished with value: 0.7703531978726306 and parameters: {'C': 1.8464319067149677, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:47,336] Trial 4 finished with value: 0.7498977226237556 and parameters: {'C': 0.10385603105219761, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:48,010] Trial 5 finished with value: 0.7733533342424656 and parameters: {'C': 9.494944128680755, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:48,093] Trial 6 finished with value: 0.5243420155461612 and parameters: {'C': 0.0031108831865037123, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:48,164] Trial 7 finished with value: 0.6780308195827083 and parameters: {'C': 0.007968008223700682, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:48,297] Trial 8 finished with value: 0.7376244374744306 and parameters: {'C': 0.06590079815265813, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7748534024273831.\n",
            "[I 2025-11-15 21:10:48,388] Trial 9 finished with value: 0.5210691395063412 and parameters: {'C': 0.0028582654266798273, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7748534024273831.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 4.481530835385039, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:11:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:11:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7749\n",
            "üèÉ View run LogisticRegression_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/69bfe5a2947645099dc8450620926344\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:11:37,033] A new study created in memory with name: no-name-48245194-ae03-4965-b4d8-6701de2a9b86\n",
            "[I 2025-11-15 21:11:37,158] Trial 0 finished with value: 0.7835810718669031 and parameters: {'C': 0.7871057111176922}. Best is trial 0 with value: 0.7835810718669031.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING LinearSVC ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:11:37,278] Trial 1 finished with value: 0.7834447020319105 and parameters: {'C': 1.6259775137305776}. Best is trial 0 with value: 0.7835810718669031.\n",
            "[I 2025-11-15 21:11:37,460] Trial 2 finished with value: 0.7831719623619255 and parameters: {'C': 5.626503759367678}. Best is trial 0 with value: 0.7835810718669031.\n",
            "[I 2025-11-15 21:11:37,561] Trial 3 finished with value: 0.7846720305468431 and parameters: {'C': 0.3007549948808244}. Best is trial 3 with value: 0.7846720305468431.\n",
            "[I 2025-11-15 21:11:37,677] Trial 4 finished with value: 0.783035592526933 and parameters: {'C': 1.0830394120875897}. Best is trial 3 with value: 0.7846720305468431.\n",
            "[I 2025-11-15 21:11:37,846] Trial 5 finished with value: 0.7834447020319105 and parameters: {'C': 4.30592685909814}. Best is trial 3 with value: 0.7846720305468431.\n",
            "[I 2025-11-15 21:11:37,996] Trial 6 finished with value: 0.783853811536888 and parameters: {'C': 3.0833139661423936}. Best is trial 3 with value: 0.7846720305468431.\n",
            "[I 2025-11-15 21:11:38,150] Trial 7 finished with value: 0.7837174417018955 and parameters: {'C': 4.029864293740345}. Best is trial 3 with value: 0.7846720305468431.\n",
            "[I 2025-11-15 21:11:38,336] Trial 8 finished with value: 0.783035592526933 and parameters: {'C': 6.854370649481714}. Best is trial 3 with value: 0.7846720305468431.\n",
            "[I 2025-11-15 21:11:38,432] Trial 9 finished with value: 0.7833083321969181 and parameters: {'C': 0.2104130179027729}. Best is trial 3 with value: 0.7846720305468431.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 0.3007549948808244}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:11:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:12:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7847\n",
            "üèÉ View run LinearSVC_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/e269465b03354530bcd64f14f1112eeb\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:12:26,259] A new study created in memory with name: no-name-cd03e18e-869c-490a-ba49-4d87dc13395a\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:12:26,524] Trial 0 finished with value: 0.785217509886813 and parameters: {'C': 0.24976894947530465}. Best is trial 0 with value: 0.785217509886813.\n",
            "[I 2025-11-15 21:12:26,730] Trial 1 finished with value: 0.784126551206873 and parameters: {'C': 0.11022736933756341}. Best is trial 0 with value: 0.785217509886813.\n",
            "[I 2025-11-15 21:12:27,205] Trial 2 finished with value: 0.785217509886813 and parameters: {'C': 4.595128875378506}. Best is trial 0 with value: 0.785217509886813.\n",
            "[I 2025-11-15 21:12:27,610] Trial 3 finished with value: 0.7856266193917906 and parameters: {'C': 3.008438504478455}. Best is trial 3 with value: 0.7856266193917906.\n",
            "[I 2025-11-15 21:12:27,873] Trial 4 finished with value: 0.7846720305468431 and parameters: {'C': 0.3661013104861995}. Best is trial 3 with value: 0.7856266193917906.\n",
            "[I 2025-11-15 21:12:28,291] Trial 5 finished with value: 0.7850811400518205 and parameters: {'C': 5.236249915151627}. Best is trial 3 with value: 0.7856266193917906.\n",
            "[I 2025-11-15 21:12:28,698] Trial 6 finished with value: 0.7856266193917906 and parameters: {'C': 3.159708932541448}. Best is trial 3 with value: 0.7856266193917906.\n",
            "[I 2025-11-15 21:12:28,962] Trial 7 finished with value: 0.7848084003818355 and parameters: {'C': 0.377930234730052}. Best is trial 3 with value: 0.7856266193917906.\n",
            "[I 2025-11-15 21:12:29,359] Trial 8 finished with value: 0.7856266193917906 and parameters: {'C': 2.3343643204352387}. Best is trial 3 with value: 0.7856266193917906.\n",
            "[I 2025-11-15 21:12:29,785] Trial 9 finished with value: 0.7853538797218055 and parameters: {'C': 4.340221384985838}. Best is trial 3 with value: 0.7856266193917906.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 3.008438504478455}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:12:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:13:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7856\n",
            "üèÉ View run LinearSVC_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/362b9c7b8c5043b898c0c721605c1adf\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:13:17,583] A new study created in memory with name: no-name-2b3ef74e-c5cb-48ee-88cf-82551a42ea1c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:13:17,799] Trial 0 finished with value: 0.7737624437474431 and parameters: {'C': 0.11263466227519324}. Best is trial 0 with value: 0.7737624437474431.\n",
            "[I 2025-11-15 21:13:18,045] Trial 1 finished with value: 0.777308059457248 and parameters: {'C': 0.3337232686716948}. Best is trial 1 with value: 0.777308059457248.\n",
            "[I 2025-11-15 21:13:18,420] Trial 2 finished with value: 0.7779899086322105 and parameters: {'C': 1.6617919280262097}. Best is trial 2 with value: 0.7779899086322105.\n",
            "[I 2025-11-15 21:13:18,908] Trial 3 finished with value: 0.7796263466521206 and parameters: {'C': 5.28902574562919}. Best is trial 3 with value: 0.7796263466521206.\n",
            "[I 2025-11-15 21:13:19,100] Trial 4 finished with value: 0.7736260739124505 and parameters: {'C': 0.11092922989994208}. Best is trial 3 with value: 0.7796263466521206.\n",
            "[I 2025-11-15 21:13:19,399] Trial 5 finished with value: 0.7781262784672031 and parameters: {'C': 0.8455269842451123}. Best is trial 3 with value: 0.7796263466521206.\n",
            "[I 2025-11-15 21:13:19,691] Trial 6 finished with value: 0.778399018137188 and parameters: {'C': 1.2755965322478338}. Best is trial 3 with value: 0.7796263466521206.\n",
            "[I 2025-11-15 21:13:19,991] Trial 7 finished with value: 0.7774444292922406 and parameters: {'C': 0.6981401502477422}. Best is trial 3 with value: 0.7796263466521206.\n",
            "[I 2025-11-15 21:13:20,404] Trial 8 finished with value: 0.778671757807173 and parameters: {'C': 2.839743499943403}. Best is trial 3 with value: 0.7796263466521206.\n",
            "[I 2025-11-15 21:13:20,653] Trial 9 finished with value: 0.7767625801172781 and parameters: {'C': 0.4332961029482291}. Best is trial 3 with value: 0.7796263466521206.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'C': 5.28902574562919}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:13:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:14:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7796\n",
            "üèÉ View run LinearSVC_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/c65451a41ec44ab4a25ff9382c612ad8\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:14:08,079] A new study created in memory with name: no-name-204832ad-9303-4472-bcf1-d92f86080b9f\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING XGBoost ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:14:15,056] Trial 0 finished with value: 0.585435701622801 and parameters: {'n_estimators': 129, 'learning_rate': 0.014380071313629403, 'max_depth': 3}. Best is trial 0 with value: 0.585435701622801.\n",
            "[I 2025-11-15 21:14:24,866] Trial 1 finished with value: 0.5437065321150961 and parameters: {'n_estimators': 73, 'learning_rate': 0.001010916468867026, 'max_depth': 5}. Best is trial 0 with value: 0.585435701622801.\n",
            "[I 2025-11-15 21:14:49,464] Trial 2 finished with value: 0.6215737078958135 and parameters: {'n_estimators': 170, 'learning_rate': 0.010543298992230167, 'max_depth': 5}. Best is trial 2 with value: 0.6215737078958135.\n",
            "[I 2025-11-15 21:14:58,097] Trial 3 finished with value: 0.5663439247238511 and parameters: {'n_estimators': 54, 'learning_rate': 0.00583766727274635, 'max_depth': 5}. Best is trial 2 with value: 0.6215737078958135.\n",
            "[I 2025-11-15 21:15:13,925] Trial 4 finished with value: 0.585162961952816 and parameters: {'n_estimators': 71, 'learning_rate': 0.006729472038015225, 'max_depth': 6}. Best is trial 2 with value: 0.6215737078958135.\n",
            "[I 2025-11-15 21:15:52,782] Trial 5 finished with value: 0.7230328651302332 and parameters: {'n_estimators': 160, 'learning_rate': 0.048172013817799286, 'max_depth': 7}. Best is trial 5 with value: 0.7230328651302332.\n",
            "[I 2025-11-15 21:16:09,092] Trial 6 finished with value: 0.6875767080321833 and parameters: {'n_estimators': 115, 'learning_rate': 0.05227121002816524, 'max_depth': 5}. Best is trial 5 with value: 0.7230328651302332.\n",
            "[I 2025-11-15 21:16:50,011] Trial 7 finished with value: 0.603709259511796 and parameters: {'n_estimators': 182, 'learning_rate': 0.004876854998142799, 'max_depth': 6}. Best is trial 5 with value: 0.7230328651302332.\n",
            "[I 2025-11-15 21:17:14,797] Trial 8 finished with value: 0.6618028092186008 and parameters: {'n_estimators': 109, 'learning_rate': 0.02424627805673485, 'max_depth': 6}. Best is trial 5 with value: 0.7230328651302332.\n",
            "[I 2025-11-15 21:18:00,490] Trial 9 finished with value: 0.6365743897449884 and parameters: {'n_estimators': 148, 'learning_rate': 0.00948930539622074, 'max_depth': 7}. Best is trial 5 with value: 0.7230328651302332.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 160, 'learning_rate': 0.048172013817799286, 'max_depth': 7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:19:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:19:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7230\n",
            "üèÉ View run XGBoost_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/766ce2b4779b42b2b219ecaa876d9611\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:19:33,035] A new study created in memory with name: no-name-23836a39-7dcc-47df-924c-3eb19c9bec2b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:19:43,739] Trial 0 finished with value: 0.5782081003681986 and parameters: {'n_estimators': 121, 'learning_rate': 0.012936622996240193, 'max_depth': 3}. Best is trial 0 with value: 0.5782081003681986.\n",
            "[I 2025-11-15 21:20:12,814] Trial 1 finished with value: 0.604254738851766 and parameters: {'n_estimators': 130, 'learning_rate': 0.009713238825723518, 'max_depth': 5}. Best is trial 1 with value: 0.604254738851766.\n",
            "[I 2025-11-15 21:20:29,675] Trial 2 finished with value: 0.6252556934406109 and parameters: {'n_estimators': 186, 'learning_rate': 0.0164493137526255, 'max_depth': 3}. Best is trial 2 with value: 0.6252556934406109.\n",
            "[I 2025-11-15 21:20:45,891] Trial 3 finished with value: 0.5716623482885586 and parameters: {'n_estimators': 171, 'learning_rate': 0.007382738116165913, 'max_depth': 3}. Best is trial 2 with value: 0.6252556934406109.\n",
            "[I 2025-11-15 21:21:11,602] Trial 4 finished with value: 0.6969862266466658 and parameters: {'n_estimators': 128, 'learning_rate': 0.0463061744720646, 'max_depth': 5}. Best is trial 4 with value: 0.6969862266466658.\n",
            "[I 2025-11-15 21:21:56,804] Trial 5 finished with value: 0.5597981726442111 and parameters: {'n_estimators': 193, 'learning_rate': 0.0012981218830618092, 'max_depth': 5}. Best is trial 4 with value: 0.6969862266466658.\n",
            "[I 2025-11-15 21:23:14,598] Trial 6 finished with value: 0.6738033546979408 and parameters: {'n_estimators': 173, 'learning_rate': 0.014505828867762093, 'max_depth': 7}. Best is trial 4 with value: 0.6969862266466658.\n",
            "[I 2025-11-15 21:24:07,397] Trial 7 finished with value: 0.6788490385926633 and parameters: {'n_estimators': 169, 'learning_rate': 0.01995706002478489, 'max_depth': 6}. Best is trial 4 with value: 0.6969862266466658.\n",
            "[I 2025-11-15 21:24:49,763] Trial 8 finished with value: 0.5707077594436111 and parameters: {'n_estimators': 179, 'learning_rate': 0.002922589832014728, 'max_depth': 5}. Best is trial 4 with value: 0.6969862266466658.\n",
            "[I 2025-11-15 21:25:21,175] Trial 9 finished with value: 0.7276694395199782 and parameters: {'n_estimators': 116, 'learning_rate': 0.07757267381768003, 'max_depth': 6}. Best is trial 9 with value: 0.7276694395199782.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 116, 'learning_rate': 0.07757267381768003, 'max_depth': 6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:26:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:26:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7277\n",
            "üèÉ View run XGBoost_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/289c0a8439b04452bba0f67c230e97d7\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:26:50,356] A new study created in memory with name: no-name-0ef2a75f-5f1c-4ba7-85fe-106e3a7cc39e\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:27:10,821] Trial 0 finished with value: 0.7282149188599482 and parameters: {'n_estimators': 153, 'learning_rate': 0.07973598582782566, 'max_depth': 4}. Best is trial 0 with value: 0.7282149188599482.\n",
            "[I 2025-11-15 21:28:45,141] Trial 1 finished with value: 0.5930724123823811 and parameters: {'n_estimators': 171, 'learning_rate': 0.0017978501245179404, 'max_depth': 7}. Best is trial 0 with value: 0.7282149188599482.\n",
            "[I 2025-11-15 21:29:19,531] Trial 2 finished with value: 0.593617891722351 and parameters: {'n_estimators': 62, 'learning_rate': 0.006715537905040577, 'max_depth': 7}. Best is trial 0 with value: 0.7282149188599482.\n",
            "[I 2025-11-15 21:29:40,543] Trial 3 finished with value: 0.6817128051275058 and parameters: {'n_estimators': 199, 'learning_rate': 0.03979285289555586, 'max_depth': 3}. Best is trial 0 with value: 0.7282149188599482.\n",
            "[I 2025-11-15 21:30:01,070] Trial 4 finished with value: 0.7295786172098732 and parameters: {'n_estimators': 131, 'learning_rate': 0.09420372197852463, 'max_depth': 4}. Best is trial 4 with value: 0.7295786172098732.\n",
            "[I 2025-11-15 21:30:20,123] Trial 5 finished with value: 0.5675712532387835 and parameters: {'n_estimators': 165, 'learning_rate': 0.005168028289374867, 'max_depth': 3}. Best is trial 4 with value: 0.7295786172098732.\n",
            "[I 2025-11-15 21:31:18,992] Trial 6 finished with value: 0.7490795036138006 and parameters: {'n_estimators': 139, 'learning_rate': 0.07735371272428565, 'max_depth': 7}. Best is trial 6 with value: 0.7490795036138006.\n",
            "[I 2025-11-15 21:32:08,842] Trial 7 finished with value: 0.5559798172644211 and parameters: {'n_estimators': 180, 'learning_rate': 0.0011597808267496438, 'max_depth': 5}. Best is trial 6 with value: 0.7490795036138006.\n",
            "[I 2025-11-15 21:32:29,149] Trial 8 finished with value: 0.5543433792445112 and parameters: {'n_estimators': 50, 'learning_rate': 0.0010141284983726537, 'max_depth': 6}. Best is trial 6 with value: 0.7490795036138006.\n",
            "[I 2025-11-15 21:33:11,765] Trial 9 finished with value: 0.5573435156143461 and parameters: {'n_estimators': 155, 'learning_rate': 0.0014869652480016412, 'max_depth': 5}. Best is trial 6 with value: 0.7490795036138006.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 139, 'learning_rate': 0.07735371272428565, 'max_depth': 7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:34:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:34:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7491\n",
            "üèÉ View run XGBoost_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/10f623cdafb84cc9a00fd633c9e56a9e\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:35:08,548] A new study created in memory with name: no-name-77434f9e-2e40-4e5f-a80d-7dc62a21cb4d\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING LightGBM ON ALL 3 SAMPLING METHODS\n",
            "================================================================================\n",
            "\n",
            "  [UNDERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:35:14,210] Trial 0 finished with value: 0.7732169644074731 and parameters: {'n_estimators': 118, 'learning_rate': 0.02593033621470207, 'num_leaves': 43}. Best is trial 0 with value: 0.7732169644074731.\n",
            "[I 2025-11-15 21:35:16,181] Trial 1 finished with value: 0.7372153279694531 and parameters: {'n_estimators': 51, 'learning_rate': 0.025414749400699346, 'num_leaves': 32}. Best is trial 0 with value: 0.7732169644074731.\n",
            "[I 2025-11-15 21:35:20,866] Trial 2 finished with value: 0.7126687576708032 and parameters: {'n_estimators': 129, 'learning_rate': 0.00404388300716934, 'num_leaves': 31}. Best is trial 0 with value: 0.7732169644074731.\n",
            "[I 2025-11-15 21:35:22,994] Trial 3 finished with value: 0.7767625801172781 and parameters: {'n_estimators': 122, 'learning_rate': 0.08803174295637799, 'num_leaves': 15}. Best is trial 3 with value: 0.7767625801172781.\n",
            "[I 2025-11-15 21:35:27,215] Trial 4 finished with value: 0.7818082640120005 and parameters: {'n_estimators': 150, 'learning_rate': 0.055888087897430924, 'num_leaves': 27}. Best is trial 4 with value: 0.7818082640120005.\n",
            "[I 2025-11-15 21:35:29,258] Trial 5 finished with value: 0.7504432019637256 and parameters: {'n_estimators': 63, 'learning_rate': 0.04640645539015349, 'num_leaves': 24}. Best is trial 4 with value: 0.7818082640120005.\n",
            "[I 2025-11-15 21:35:33,200] Trial 6 finished with value: 0.781126414837038 and parameters: {'n_estimators': 154, 'learning_rate': 0.08733640951105368, 'num_leaves': 25}. Best is trial 4 with value: 0.7818082640120005.\n",
            "[I 2025-11-15 21:35:35,515] Trial 7 finished with value: 0.7108959498159008 and parameters: {'n_estimators': 60, 'learning_rate': 0.0050440146739065975, 'num_leaves': 32}. Best is trial 4 with value: 0.7818082640120005.\n",
            "[I 2025-11-15 21:35:41,363] Trial 8 finished with value: 0.778671757807173 and parameters: {'n_estimators': 170, 'learning_rate': 0.03528493603861318, 'num_leaves': 28}. Best is trial 4 with value: 0.7818082640120005.\n",
            "[I 2025-11-15 21:35:43,624] Trial 9 finished with value: 0.7738988135824356 and parameters: {'n_estimators': 103, 'learning_rate': 0.08500748487607573, 'num_leaves': 17}. Best is trial 4 with value: 0.7818082640120005.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 150, 'learning_rate': 0.055888087897430924, 'num_leaves': 27}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:36:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:36:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7818\n",
            "üèÉ View run LightGBM_undersampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/b2be38a31267493ebe6b76a48d7e4ba3\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:36:46,531] A new study created in memory with name: no-name-c8d0163c-af1a-4b42-b2ed-ea2b8f880c48\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [OVERSAMPLING] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:36:52,091] Trial 0 finished with value: 0.7369425882994681 and parameters: {'n_estimators': 114, 'learning_rate': 0.020316676907460713, 'num_leaves': 21}. Best is trial 0 with value: 0.7369425882994681.\n",
            "[I 2025-11-15 21:37:00,355] Trial 1 finished with value: 0.6999863630165007 and parameters: {'n_estimators': 181, 'learning_rate': 0.00596098005881663, 'num_leaves': 21}. Best is trial 0 with value: 0.7369425882994681.\n",
            "[I 2025-11-15 21:37:03,908] Trial 2 finished with value: 0.6693031501431883 and parameters: {'n_estimators': 78, 'learning_rate': 0.0013761861657969067, 'num_leaves': 19}. Best is trial 0 with value: 0.7369425882994681.\n",
            "[I 2025-11-15 21:37:17,965] Trial 3 finished with value: 0.7392608754943406 and parameters: {'n_estimators': 134, 'learning_rate': 0.0010032308171960568, 'num_leaves': 49}. Best is trial 3 with value: 0.7392608754943406.\n",
            "[I 2025-11-15 21:37:26,208] Trial 4 finished with value: 0.7383062866493931 and parameters: {'n_estimators': 88, 'learning_rate': 0.003422886786190168, 'num_leaves': 47}. Best is trial 3 with value: 0.7392608754943406.\n",
            "[I 2025-11-15 21:37:30,954] Trial 5 finished with value: 0.7391245056593482 and parameters: {'n_estimators': 99, 'learning_rate': 0.025325388159803768, 'num_leaves': 21}. Best is trial 3 with value: 0.7392608754943406.\n",
            "[I 2025-11-15 21:37:42,883] Trial 6 finished with value: 0.6975317059866357 and parameters: {'n_estimators': 192, 'learning_rate': 0.0017999108573922408, 'num_leaves': 27}. Best is trial 3 with value: 0.7392608754943406.\n",
            "[I 2025-11-15 21:37:56,288] Trial 7 finished with value: 0.7159416337106232 and parameters: {'n_estimators': 179, 'learning_rate': 0.0015162859050586056, 'num_leaves': 35}. Best is trial 3 with value: 0.7392608754943406.\n",
            "[I 2025-11-15 21:38:04,890] Trial 8 finished with value: 0.783853811536888 and parameters: {'n_estimators': 159, 'learning_rate': 0.04833901902672037, 'num_leaves': 25}. Best is trial 8 with value: 0.783853811536888.\n",
            "[I 2025-11-15 21:38:09,958] Trial 9 finished with value: 0.6826673939724532 and parameters: {'n_estimators': 134, 'learning_rate': 0.008646125610442704, 'num_leaves': 17}. Best is trial 8 with value: 0.783853811536888.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 159, 'learning_rate': 0.04833901902672037, 'num_leaves': 25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:38:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:39:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7839\n",
            "üèÉ View run LightGBM_oversampling_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/cccd0adfe2a142d59f4c42e6a3efcfed\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:39:16,161] A new study created in memory with name: no-name-0966948e-706c-4d80-a445-dc61bfb3f107\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  [ADASYN] Running HPT (10 trials)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-15 21:39:20,347] Trial 0 finished with value: 0.7486703941088231 and parameters: {'n_estimators': 50, 'learning_rate': 0.010454865501484783, 'num_leaves': 49}. Best is trial 0 with value: 0.7486703941088231.\n",
            "[I 2025-11-15 21:39:29,109] Trial 1 finished with value: 0.785490249556798 and parameters: {'n_estimators': 115, 'learning_rate': 0.03150369418385284, 'num_leaves': 46}. Best is trial 1 with value: 0.785490249556798.\n",
            "[I 2025-11-15 21:39:38,992] Trial 2 finished with value: 0.7238510841401882 and parameters: {'n_estimators': 148, 'learning_rate': 0.002997506411675642, 'num_leaves': 35}. Best is trial 1 with value: 0.785490249556798.\n",
            "[I 2025-11-15 21:39:47,769] Trial 3 finished with value: 0.7858993590617755 and parameters: {'n_estimators': 97, 'learning_rate': 0.03593581755262887, 'num_leaves': 48}. Best is trial 3 with value: 0.7858993590617755.\n",
            "[I 2025-11-15 21:39:57,298] Trial 4 finished with value: 0.7908086731215055 and parameters: {'n_estimators': 196, 'learning_rate': 0.05437133178453067, 'num_leaves': 25}. Best is trial 4 with value: 0.7908086731215055.\n",
            "[I 2025-11-15 21:40:02,180] Trial 5 finished with value: 0.7134869766807582 and parameters: {'n_estimators': 74, 'learning_rate': 0.0019874336604530107, 'num_leaves': 30}. Best is trial 4 with value: 0.7908086731215055.\n",
            "[I 2025-11-15 21:40:07,502] Trial 6 finished with value: 0.7328514932496931 and parameters: {'n_estimators': 65, 'learning_rate': 0.0038247813288196423, 'num_leaves': 41}. Best is trial 4 with value: 0.7908086731215055.\n",
            "[I 2025-11-15 21:40:13,737] Trial 7 finished with value: 0.7693986090276831 and parameters: {'n_estimators': 187, 'learning_rate': 0.03454570308112521, 'num_leaves': 15}. Best is trial 4 with value: 0.7908086731215055.\n",
            "[I 2025-11-15 21:40:18,016] Trial 8 finished with value: 0.6915314332469658 and parameters: {'n_estimators': 133, 'learning_rate': 0.013620531645548814, 'num_leaves': 13}. Best is trial 4 with value: 0.7908086731215055.\n",
            "[I 2025-11-15 21:40:32,706] Trial 9 finished with value: 0.7312150552297831 and parameters: {'n_estimators': 197, 'learning_rate': 0.0014276268112900794, 'num_leaves': 36}. Best is trial 4 with value: 0.7908086731215055.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Best params: {'n_estimators': 196, 'learning_rate': 0.05437133178453067, 'num_leaves': 25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/15 21:41:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/15 21:41:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úì Logged with Accuracy: 0.7908\n",
            "üèÉ View run LightGBM_adasyn_TFIDF(1000)_HPT at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17/runs/cf778d451434433fbe988012a3f0b387\n",
            "üß™ View experiment at: http://ec2-54-211-18-166.compute-1.amazonaws.com:5000/#/experiments/17\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "‚úì ALL MODELS TRAINED AND LOGGED\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def train_individual_models_with_hpt(model_name, tune_func):\n",
        "    \"\"\"\n",
        "    Train separate models on each resampling method and log each one.\n",
        "    This allows us to find which algorithm + sampling method combination works best.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TRAINING {model_name} ON ALL 3 SAMPLING METHODS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    for method, (X_resample, y_resample) in datasets.items():\n",
        "        print(f\"\\n  [{method.upper()}] Running HPT ({N_TRIALS} trials)...\")\n",
        "        \n",
        "        # Tune hyperparameters\n",
        "        best_params = tune_func(X_resample, y_resample)\n",
        "        print(f\"    Best params: {best_params}\")\n",
        "        \n",
        "        # Train model with best params\n",
        "        if model_name == 'LogisticRegression':\n",
        "            model = LogisticRegression(random_state=42, multi_class='auto', max_iter=1000, **best_params)\n",
        "        elif model_name == 'LinearSVC':\n",
        "            model = LinearSVC(random_state=42, max_iter=1000, dual='auto', **best_params)\n",
        "        elif model_name == 'XGBoost':\n",
        "            model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1, **best_params)\n",
        "        elif model_name == 'LightGBM':\n",
        "            model = LGBMClassifier(random_state=42, verbose=-1, **best_params)\n",
        "        \n",
        "        model.fit(X_resample, y_resample)\n",
        "        \n",
        "        # Log each model separately\n",
        "        log_mlflow(f\"{model_name}\", model, params=best_params, imbalance_method=method)\n",
        "    \n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "# Execute Training\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING MODEL TRAINING WITH ALL SAMPLING METHODS\")\n",
        "print(\"=\"*80)\n",
        "print(\"Strategy: Train each algorithm on all 3 sampling methods separately\")\n",
        "print(\"This creates 12 models (4 algorithms √ó 3 sampling methods)\")\n",
        "print(\"MLflow will track all and identify the best combination\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Train baseline\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"BASELINE: MultinomialNB (No HPT)\")\n",
        "print(f\"{'='*80}\")\n",
        "mnb = MultinomialNB(alpha=1.0)\n",
        "mnb.fit(X_train_under, y_train_under)\n",
        "log_mlflow('MultinomialNB', mnb, params={'alpha': 1.0}, imbalance_method='undersampling')\n",
        "\n",
        "# Train all models on all sampling methods individually\n",
        "models_to_tune = [\n",
        "    ('LogisticRegression', tune_logistic_regression),\n",
        "    ('LinearSVC', tune_linear_svc),\n",
        "    ('XGBoost', tune_xgboost),\n",
        "    ('LightGBM', tune_lightgbm)\n",
        "]\n",
        "\n",
        "for model_name, tune_func in models_to_tune:\n",
        "    train_individual_models_with_hpt(model_name, tune_func)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úì ALL MODELS TRAINED AND LOGGED\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusion and Next Steps\n",
        "The complete set of model performances, including optimized hyperparameters, is now logged in the MLflow UI. The next step is typically stacking or selecting the single best performing model based on comprehensive evaluation metrics, especially F1-scores for the minority classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FETCHING RESULTS FROM EXPERIMENT\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TOP 10 MODELS (Sorted by Composite Score: Avg of Accuracy & Weighted F1)\n",
            "================================================================================\n",
            "         algo_name imbalance_handling  accuracy  weighted_f1  composite_score     2_f1\n",
            "          LightGBM             adasyn  0.790809     0.787167         0.788988 0.658624\n",
            "         LinearSVC       oversampling  0.785627     0.783244         0.784435 0.662496\n",
            "         LinearSVC      undersampling  0.784672     0.782359         0.783516 0.665629\n",
            "          LightGBM       oversampling  0.783854     0.780722         0.782288 0.653920\n",
            "          LightGBM      undersampling  0.781808     0.779463         0.780636 0.658393\n",
            "LogisticRegression      undersampling  0.780990     0.779422         0.780206 0.659724\n",
            "LogisticRegression       oversampling  0.779899     0.778274         0.779086 0.654291\n",
            "         LinearSVC             adasyn  0.779626     0.777610         0.778618 0.644207\n",
            "LogisticRegression             adasyn  0.774853     0.773705         0.774279 0.638048\n",
            "           XGBoost             adasyn  0.749080     0.745782         0.747431 0.621231\n",
            "\n",
            "================================================================================\n",
            "RANKINGS BY DIFFERENT METRICS\n",
            "================================================================================\n",
            "\n",
            "üìä Top 5 by Accuracy:\n",
            "  LightGBM                  (adasyn         ) - Accuracy: 0.7908\n",
            "  LinearSVC                 (oversampling   ) - Accuracy: 0.7856\n",
            "  LinearSVC                 (undersampling  ) - Accuracy: 0.7847\n",
            "  LightGBM                  (oversampling   ) - Accuracy: 0.7839\n",
            "  LightGBM                  (undersampling  ) - Accuracy: 0.7818\n",
            "\n",
            "üìä Top 5 by Weighted F1-Score:\n",
            "  LightGBM                  (adasyn         ) - Weighted F1: 0.7872\n",
            "  LinearSVC                 (oversampling   ) - Weighted F1: 0.7832\n",
            "  LinearSVC                 (undersampling  ) - Weighted F1: 0.7824\n",
            "  LightGBM                  (oversampling   ) - Weighted F1: 0.7807\n",
            "  LightGBM                  (undersampling  ) - Weighted F1: 0.7795\n",
            "\n",
            "üìä Top 5 by Minority Class (2) F1-Score:\n",
            "  LinearSVC                 (undersampling  ) - Class 2 F1: 0.6656\n",
            "  LinearSVC                 (oversampling   ) - Class 2 F1: 0.6625\n",
            "  LogisticRegression        (undersampling  ) - Class 2 F1: 0.6597\n",
            "  LightGBM                  (adasyn         ) - Class 2 F1: 0.6586\n",
            "  LightGBM                  (undersampling  ) - Class 2 F1: 0.6584\n",
            "\n",
            "================================================================================\n",
            "BEST SAMPLING METHOD FOR EACH ALGORITHM\n",
            "================================================================================\n",
            "\n",
            "LightGBM:\n",
            "  Best Sampling: adasyn\n",
            "  Accuracy: 0.7908\n",
            "  Weighted F1: 0.7872\n",
            "  Minority F1: 0.6586\n",
            "\n",
            "LinearSVC:\n",
            "  Best Sampling: oversampling\n",
            "  Accuracy: 0.7856\n",
            "  Weighted F1: 0.7832\n",
            "  Minority F1: 0.6625\n",
            "\n",
            "LogisticRegression:\n",
            "  Best Sampling: undersampling\n",
            "  Accuracy: 0.7810\n",
            "  Weighted F1: 0.7794\n",
            "  Minority F1: 0.6597\n",
            "\n",
            "XGBoost:\n",
            "  Best Sampling: adasyn\n",
            "  Accuracy: 0.7491\n",
            "  Weighted F1: 0.7458\n",
            "  Minority F1: 0.6212\n",
            "\n",
            "MultinomialNB:\n",
            "  Best Sampling: undersampling\n",
            "  Accuracy: 0.7000\n",
            "  Weighted F1: 0.7039\n",
            "  Minority F1: 0.5917\n",
            "\n",
            "================================================================================\n",
            "üèÜ BEST OVERALL MODEL (by Composite Score)\n",
            "================================================================================\n",
            "Algorithm: LightGBM\n",
            "Imbalance Handling: adasyn\n",
            "Composite Score: 0.7890\n",
            "Accuracy: 0.7908\n",
            "Weighted F1-Score: 0.7872\n",
            "Class 0 F1: 0.8392\n",
            "Class 1 F1: 0.8127\n",
            "Class 2 (Minority) F1: 0.6586\n",
            "Run ID: cf778d451434433fbe988012a3f0b387\n",
            "================================================================================\n",
            "\n",
            "üí° Key Insights:\n",
            "   ‚úì Each algorithm trained on undersampling, oversampling, and ADASYN\n",
            "   ‚úì Best model selected from all 12 combinations (4 algos √ó 3 methods)\n",
            "   ‚úì Composite Score balances accuracy with class-wise F1 performance\n",
            "   ‚úì This approach avoids ensemble voting that may reduce performance\n"
          ]
        }
      ],
      "source": [
        "OPTIMAL_METRIC = \"weighted avg_f1-score\"\n",
        "\n",
        "try:\n",
        "    client = mlflow.tracking.MlflowClient()\n",
        "    experiment = client.get_experiment_by_name(\"Model Comparision (TFIDF Bigram 1000 + Ensemble Imbalance) - Exp 5\")\n",
        "    \n",
        "    if experiment:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"FETCHING RESULTS FROM EXPERIMENT\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        runs = client.search_runs(experiment_ids=experiment_id)\n",
        "        run_data = []\n",
        "        \n",
        "        for run in runs:\n",
        "            metrics = run.data.metrics\n",
        "            params = run.data.params\n",
        "            \n",
        "            run_data.append({\n",
        "                'run_id': run.info.run_id,\n",
        "                'algo_name': params.get('algo_name', 'N/A'),\n",
        "                'imbalance_handling': params.get('imbalance_handling', 'N/A'),\n",
        "                'accuracy': metrics.get('accuracy', 0.0),\n",
        "                'weighted_f1': metrics.get(OPTIMAL_METRIC, 0.0),\n",
        "                '0_f1': metrics.get('0_f1-score', 0.0),\n",
        "                '1_f1': metrics.get('1_f1-score', 0.0),\n",
        "                '2_f1': metrics.get('2_f1-score', 0.0),\n",
        "                'run_name': run.data.tags.get('mlflow.runName')\n",
        "            })\n",
        "\n",
        "        df_results = pd.DataFrame(run_data)\n",
        "        \n",
        "        # Create composite score: average of accuracy and weighted F1\n",
        "        df_results['composite_score'] = (df_results['accuracy'] + df_results['weighted_f1']) / 2\n",
        "        \n",
        "        # Sort by composite score\n",
        "        df_results = df_results.sort_values(by='composite_score', ascending=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"TOP 10 MODELS (Sorted by Composite Score: Avg of Accuracy & Weighted F1)\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results[['algo_name', 'imbalance_handling', 'accuracy', \n",
        "                         'weighted_f1', 'composite_score', '2_f1']].head(10).to_string(index=False))\n",
        "        \n",
        "        # Rankings by different metrics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RANKINGS BY DIFFERENT METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(\"\\nüìä Top 5 by Accuracy:\")\n",
        "        top_acc = df_results.nlargest(5, 'accuracy')\n",
        "        for idx, row in top_acc.iterrows():\n",
        "            print(f\"  {row['algo_name']:25s} ({row['imbalance_handling']:15s}) - Accuracy: {row['accuracy']:.4f}\")\n",
        "        \n",
        "        print(\"\\nüìä Top 5 by Weighted F1-Score:\")\n",
        "        top_f1 = df_results.nlargest(5, 'weighted_f1')\n",
        "        for idx, row in top_f1.iterrows():\n",
        "            print(f\"  {row['algo_name']:25s} ({row['imbalance_handling']:15s}) - Weighted F1: {row['weighted_f1']:.4f}\")\n",
        "        \n",
        "        print(\"\\nüìä Top 5 by Minority Class (2) F1-Score:\")\n",
        "        top_minority = df_results.nlargest(5, '2_f1')\n",
        "        for idx, row in top_minority.iterrows():\n",
        "            print(f\"  {row['algo_name']:25s} ({row['imbalance_handling']:15s}) - Class 2 F1: {row['2_f1']:.4f}\")\n",
        "        \n",
        "        # Algorithm + Sampling Method Analysis\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"BEST SAMPLING METHOD FOR EACH ALGORITHM\")\n",
        "        print(\"=\"*80)\n",
        "        for algo in df_results['algo_name'].unique():\n",
        "            if algo != 'N/A':\n",
        "                algo_df = df_results[df_results['algo_name'] == algo]\n",
        "                best_row = algo_df.iloc[0]\n",
        "                print(f\"\\n{algo}:\")\n",
        "                print(f\"  Best Sampling: {best_row['imbalance_handling']}\")\n",
        "                print(f\"  Accuracy: {best_row['accuracy']:.4f}\")\n",
        "                print(f\"  Weighted F1: {best_row['weighted_f1']:.4f}\")\n",
        "                print(f\"  Minority F1: {best_row['2_f1']:.4f}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üèÜ BEST OVERALL MODEL (by Composite Score)\")\n",
        "        print(\"=\"*80)\n",
        "        best = df_results.iloc[0]\n",
        "        print(f\"Algorithm: {best['algo_name']}\")\n",
        "        print(f\"Imbalance Handling: {best['imbalance_handling']}\")\n",
        "        print(f\"Composite Score: {best['composite_score']:.4f}\")\n",
        "        print(f\"Accuracy: {best['accuracy']:.4f}\")\n",
        "        print(f\"Weighted F1-Score: {best['weighted_f1']:.4f}\")\n",
        "        print(f\"Class 0 F1: {best['0_f1']:.4f}\")\n",
        "        print(f\"Class 1 F1: {best['1_f1']:.4f}\")\n",
        "        print(f\"Class 2 (Minority) F1: {best['2_f1']:.4f}\")\n",
        "        print(f\"Run ID: {best['run_id']}\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(\"\\nüí° Key Insights:\")\n",
        "        print(\"   ‚úì Each algorithm trained on undersampling, oversampling, and ADASYN\")\n",
        "        print(\"   ‚úì Best model selected from all 12 combinations (4 algos √ó 3 methods)\")\n",
        "        print(\"   ‚úì Composite Score balances accuracy with class-wise F1 performance\")\n",
        "        print(\"   ‚úì This approach avoids ensemble voting that may reduce performance\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
